{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨트롤 할 수 있게 수치해석 모듈인 numpy와 ~~ 다시\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity11.ipynb  data\t\t    Exercise17.ipynb\r\n",
      "Activity12.ipynb  Exercise16.ipynb  Exercise18.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽어보기\n",
    "\n",
    "!ls Applied-Deep-Learning-with-Keras/Lesson06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flu.csv  Health_Data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson06/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient_id,Age,Admission_type,PreExistingDisease,PreviousSurgery,Gender,Smoker,Homeless,DaysinHospital,Readmitted\r\n",
      "1,33,Urgent,Y,0,M,1,0,1,0\r\n",
      "2,34,Emergency,N,0,M,1,0,22,0\r\n",
      "3,88,Trauma,Y,1,M,1,1,100,1\r\n",
      "4,56,Elective,Y,0,M,1,0,2,0\r\n",
      "5,45,Trauma,Y,0,M,1,0,34,0\r\n",
      "6,23,Elective,N,0,M,0,0,123,0\r\n",
      "7,67,Elective,N,0,M,0,0,23,0\r\n",
      "8,55,Elective,N,0,M,1,0,123,1\r\n",
      "9,77,Trauma,N,0,F,1,0,44,0\r\n"
     ]
    }
   ],
   "source": [
    "!head Applied-Deep-Learning-with-Keras/Lesson06/data/Health_Data.csv\n",
    "\n",
    "# !head는 리눅스 상에 명령어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = pd.read_csv(\"Applied-Deep-Learning-with-Keras/Lesson06/data/Health_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_type</th>\n",
       "      <th>PreExistingDisease</th>\n",
       "      <th>PreviousSurgery</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Homeless</th>\n",
       "      <th>DaysinHospital</th>\n",
       "      <th>Readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>Elective</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>Elective</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>Elective</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "      <td>Elective</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>77</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Newborn</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Newborn</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Newborn</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Newborn</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>54</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>Elective</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>Elective</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>90</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>54</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>78</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient_id  Age Admission_type PreExistingDisease  PreviousSurgery Gender  \\\n",
       "0            1   33         Urgent                  Y                0      M   \n",
       "1            2   34      Emergency                  N                0      M   \n",
       "2            3   88         Trauma                  Y                1      M   \n",
       "3            4   56       Elective                  Y                0      M   \n",
       "4            5   45         Trauma                  Y                0      M   \n",
       "5            6   23       Elective                  N                0      M   \n",
       "6            7   67       Elective                  N                0      M   \n",
       "7            8   55       Elective                  N                0      M   \n",
       "8            9   77         Trauma                  N                0      F   \n",
       "9           10   88      Emergency                  N                0      M   \n",
       "10          11   76         Urgent                  N                0      F   \n",
       "11          12   64         Urgent                  N                0      F   \n",
       "12          13   53         Urgent                  N                0      F   \n",
       "13          14    0        Newborn                  N                0      M   \n",
       "14          15    0        Newborn                  N                0      F   \n",
       "15          16    0        Newborn                  N                0      M   \n",
       "16          17    0        Newborn                  N                0      F   \n",
       "17          18   54         Urgent                  Y                1      M   \n",
       "18          19    5      Emergency                  Y                1      M   \n",
       "19          20    4      Emergency                  Y                0      F   \n",
       "20          21    4         Trauma                  Y                0      M   \n",
       "21          22    5         Trauma                  N                0      F   \n",
       "22          23    6       Elective                  N                0      F   \n",
       "23          24    7       Elective                  N                0      M   \n",
       "24          25   33         Trauma                  N                0      F   \n",
       "25          26   32         Trauma                  N                0      F   \n",
       "26          27   90         Urgent                  N                1      M   \n",
       "27          28   54         Urgent                  N                0      M   \n",
       "28          29    6         Urgent                  N                0      M   \n",
       "29          30   78      Emergency                  N                0      F   \n",
       "\n",
       "    Smoker  Homeless  DaysinHospital  Readmitted  \n",
       "0        1         0               1           0  \n",
       "1        1         0              22           0  \n",
       "2        1         1             100           1  \n",
       "3        1         0               2           0  \n",
       "4        1         0              34           0  \n",
       "5        0         0             123           0  \n",
       "6        0         0              23           0  \n",
       "7        1         0             123           1  \n",
       "8        1         0              44           0  \n",
       "9        1         0               3           1  \n",
       "10       1         0               2           1  \n",
       "11       1         1              45           0  \n",
       "12       0         1              32           0  \n",
       "13       0         0              33           0  \n",
       "14       0         0              22           0  \n",
       "15       0         0               7           0  \n",
       "16       0         0               7           0  \n",
       "17       1         0              32           0  \n",
       "18       1         0              43           0  \n",
       "19       1         0              32           0  \n",
       "20       1         0              46           0  \n",
       "21       1         0              54           0  \n",
       "22       1         0              90           0  \n",
       "23       1         0              76           0  \n",
       "24       1         0              44           0  \n",
       "25       1         0              78           0  \n",
       "26       1         0               5           0  \n",
       "27       1         0               4           0  \n",
       "28       1         0               4           0  \n",
       "29       1         0              96           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>PreviousSurgery</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Homeless</th>\n",
       "      <th>DaysinHospital</th>\n",
       "      <th>Readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>357.00000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>357.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>179.00000</td>\n",
       "      <td>42.574230</td>\n",
       "      <td>0.341737</td>\n",
       "      <td>0.596639</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>43.182073</td>\n",
       "      <td>0.193277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>103.20126</td>\n",
       "      <td>29.274624</td>\n",
       "      <td>0.474957</td>\n",
       "      <td>0.491261</td>\n",
       "      <td>0.485606</td>\n",
       "      <td>47.362609</td>\n",
       "      <td>0.395423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.00000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>179.00000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>268.00000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>357.00000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>352.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Patient_id         Age  PreviousSurgery      Smoker    Homeless  \\\n",
       "count   357.00000  357.000000       357.000000  357.000000  357.000000   \n",
       "mean    179.00000   42.574230         0.341737    0.596639    0.378151   \n",
       "std     103.20126   29.274624         0.474957    0.491261    0.485606   \n",
       "min       1.00000    0.000000         0.000000    0.000000    0.000000   \n",
       "25%      90.00000   14.000000         0.000000    0.000000    0.000000   \n",
       "50%     179.00000   35.000000         0.000000    1.000000    0.000000   \n",
       "75%     268.00000   67.000000         1.000000    1.000000    1.000000   \n",
       "max     357.00000   96.000000         1.000000    1.000000    1.000000   \n",
       "\n",
       "       DaysinHospital  Readmitted  \n",
       "count      357.000000  357.000000  \n",
       "mean        43.182073    0.193277  \n",
       "std         47.362609    0.395423  \n",
       "min          1.000000    0.000000  \n",
       "25%         12.000000    0.000000  \n",
       "50%         32.000000    0.000000  \n",
       "75%         55.000000    0.000000  \n",
       "max        352.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정보에 대한 요약해보기\n",
    "patient_data.describe()\n",
    "\n",
    "# 환자 수 : 357명\n",
    "# 나이 : 보통 40대 (평균) - 표준편차가 29인거 보면 10대도 있고 한 것!\n",
    "\n",
    "# 평균 - 산술평균(일반적인 평균), 기하평균, \n",
    "# 평균을 해지는 것은 이상치들(outlier)!  -->  잘못된 결과를 초래할 수 있음.\n",
    "# 현실에도 이상치 존재하기 때문에 평균 데이터만 믿으면 잘못된 결과 초래할 수 있음.\n",
    "\n",
    "# 그래서 나타나게 된 것이 사분위수!! (평균의 또 다른 정의!)\n",
    "\n",
    "# 평균 - 산술평균, 사분위수의 50%(중앙값), 최빈값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admission_type</th>\n",
       "      <th>PreExistingDisease</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Urgent</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>131</td>\n",
       "      <td>228</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Admission_type PreExistingDisease Gender\n",
       "count             357                357    357\n",
       "unique              5                  2      2\n",
       "top            Urgent                  N      F\n",
       "freq              131                228    186"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 범주형자료도 정보를 확인해볼 수 있음.\n",
    "\n",
    "patient_data.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_type</th>\n",
       "      <th>PreExistingDisease</th>\n",
       "      <th>PreviousSurgery</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Homeless</th>\n",
       "      <th>DaysinHospital</th>\n",
       "      <th>Readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>Urgent</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>Elective</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_id  Age Admission_type PreExistingDisease  PreviousSurgery Gender  \\\n",
       "0           1   33         Urgent                  Y                0      M   \n",
       "1           2   34      Emergency                  N                0      M   \n",
       "2           3   88         Trauma                  Y                1      M   \n",
       "3           4   56       Elective                  Y                0      M   \n",
       "4           5   45         Trauma                  Y                0      M   \n",
       "\n",
       "   Smoker  Homeless  DaysinHospital  Readmitted  \n",
       "0       1         0               1           0  \n",
       "1       1         0              22           0  \n",
       "2       1         1             100           1  \n",
       "3       1         0               2           0  \n",
       "4       1         0              34           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_dummies in module pandas.core.reshape.reshape:\n",
      "\n",
      "get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False, columns=None, sparse=False, drop_first=False, dtype=None) -> 'DataFrame'\n",
      "    Convert categorical variable into dummy/indicator variables.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : array-like, Series, or DataFrame\n",
      "        Data of which to get dummy indicators.\n",
      "    prefix : str, list of str, or dict of str, default None\n",
      "        String to append DataFrame column names.\n",
      "        Pass a list with length equal to the number of columns\n",
      "        when calling get_dummies on a DataFrame. Alternatively, `prefix`\n",
      "        can be a dictionary mapping column names to prefixes.\n",
      "    prefix_sep : str, default '_'\n",
      "        If appending prefix, separator/delimiter to use. Or pass a\n",
      "        list or dictionary as with `prefix`.\n",
      "    dummy_na : bool, default False\n",
      "        Add a column to indicate NaNs, if False NaNs are ignored.\n",
      "    columns : list-like, default None\n",
      "        Column names in the DataFrame to be encoded.\n",
      "        If `columns` is None then all the columns with\n",
      "        `object` or `category` dtype will be converted.\n",
      "    sparse : bool, default False\n",
      "        Whether the dummy-encoded columns should be backed by\n",
      "        a :class:`SparseArray` (True) or a regular NumPy array (False).\n",
      "    drop_first : bool, default False\n",
      "        Whether to get k-1 dummies out of k categorical levels by removing the\n",
      "        first level.\n",
      "    dtype : dtype, default np.uint8\n",
      "        Data type for new columns. Only a single dtype is allowed.\n",
      "    \n",
      "        .. versionadded:: 0.23.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        Dummy-coded data.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    Series.str.get_dummies : Convert Series to dummy codes.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> s = pd.Series(list('abca'))\n",
      "    \n",
      "    >>> pd.get_dummies(s)\n",
      "       a  b  c\n",
      "    0  1  0  0\n",
      "    1  0  1  0\n",
      "    2  0  0  1\n",
      "    3  1  0  0\n",
      "    \n",
      "    >>> s1 = ['a', 'b', np.nan]\n",
      "    \n",
      "    >>> pd.get_dummies(s1)\n",
      "       a  b\n",
      "    0  1  0\n",
      "    1  0  1\n",
      "    2  0  0\n",
      "    \n",
      "    >>> pd.get_dummies(s1, dummy_na=True)\n",
      "       a  b  NaN\n",
      "    0  1  0    0\n",
      "    1  0  1    0\n",
      "    2  0  0    1\n",
      "    \n",
      "    >>> df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'],\n",
      "    ...                    'C': [1, 2, 3]})\n",
      "    \n",
      "    >>> pd.get_dummies(df, prefix=['col1', 'col2'])\n",
      "       C  col1_a  col1_b  col2_a  col2_b  col2_c\n",
      "    0  1       1       0       0       1       0\n",
      "    1  2       0       1       1       0       0\n",
      "    2  3       1       0       0       0       1\n",
      "    \n",
      "    >>> pd.get_dummies(pd.Series(list('abcaa')))\n",
      "       a  b  c\n",
      "    0  1  0  0\n",
      "    1  0  1  0\n",
      "    2  0  0  1\n",
      "    3  1  0  0\n",
      "    4  1  0  0\n",
      "    \n",
      "    >>> pd.get_dummies(pd.Series(list('abcaa')), drop_first=True)\n",
      "       b  c\n",
      "    0  0  0\n",
      "    1  1  0\n",
      "    2  0  1\n",
      "    3  0  0\n",
      "    4  0  0\n",
      "    \n",
      "    >>> pd.get_dummies(pd.Series(list('abc')), dtype=float)\n",
      "         a    b    c\n",
      "    0  1.0  0.0  0.0\n",
      "    1  0.0  1.0  0.0\n",
      "    2  0.0  0.0  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.get_dummies)\n",
    "\n",
    "# 카테고리화할 수 있는 변수들을 더미/indicator 변수로 변화해준다.\n",
    "# 카테고리화가 가능한 변수들의 빈도수를 체크해볼 수 있다.\n",
    "# 인코딩할 때도 사용했었음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.indexing._iLocIndexer object at 0x7fdff80787d0>\n"
     ]
    }
   ],
   "source": [
    "X = patient_data.iloc\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      33\n",
      "1      34\n",
      "2      88\n",
      "3      56\n",
      "4      45\n",
      "       ..\n",
      "352    14\n",
      "353    45\n",
      "354    67\n",
      "355    43\n",
      "356     2\n",
      "Name: Age, Length: 357, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터에서 1열만 출력\n",
    "X = patient_data.iloc[:, 1]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age Admission_type PreExistingDisease  PreviousSurgery Gender  Smoker  \\\n",
      "0     33         Urgent                  Y                0      M       1   \n",
      "1     34      Emergency                  N                0      M       1   \n",
      "2     88         Trauma                  Y                1      M       1   \n",
      "3     56       Elective                  Y                0      M       1   \n",
      "4     45         Trauma                  Y                0      M       1   \n",
      "..   ...            ...                ...              ...    ...     ...   \n",
      "352   14         Trauma                  Y                1      M       1   \n",
      "353   45         Trauma                  N                0      F       1   \n",
      "354   67         Trauma                  N                1      M       1   \n",
      "355   43         Trauma                  Y                1      M       0   \n",
      "356    2         Trauma                  Y                1      F       0   \n",
      "\n",
      "     Homeless  DaysinHospital  \n",
      "0           0               1  \n",
      "1           0              22  \n",
      "2           1             100  \n",
      "3           0               2  \n",
      "4           0              34  \n",
      "..        ...             ...  \n",
      "352         1               2  \n",
      "353         1               2  \n",
      "354         1               2  \n",
      "355         1               2  \n",
      "356         1               2  \n",
      "\n",
      "[357 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "X = patient_data.iloc[:, 1:9]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "352    0\n",
      "353    0\n",
      "354    0\n",
      "355    0\n",
      "356    0\n",
      "Name: Readmitted, Length: 357, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 다시~~\n",
    "# 재이건율?\n",
    "y = patient_data.iloc[:, 9]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Urgent\n",
      "1      Emergency\n",
      "2         Trauma\n",
      "3       Elective\n",
      "4         Trauma\n",
      "         ...    \n",
      "352       Trauma\n",
      "353       Trauma\n",
      "354       Trauma\n",
      "355       Trauma\n",
      "356       Trauma\n",
      "Name: Admission_type, Length: 357, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpecType = pd.get_dummies(X.iloc[:, 1], drop_first = True, prefix = 'SpecType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SpecType_Emergency  SpecType_Newborn  SpecType_Trauma  SpecType_Urgent\n",
      "0                     0                 0                0                1\n",
      "1                     1                 0                0                0\n",
      "2                     0                 0                1                0\n",
      "3                     0                 0                0                0\n",
      "4                     0                 0                1                0\n",
      "..                  ...               ...              ...              ...\n",
      "352                   0                 0                1                0\n",
      "353                   0                 0                1                0\n",
      "354                   0                 0                1                0\n",
      "355                   0                 0                1                0\n",
      "356                   0                 0                1                0\n",
      "\n",
      "[357 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 인코딩해주기\n",
    "# 긴급하지 않은 환자(Elective)를 제거하고 데이터가 분리되었음!\n",
    "\n",
    "print(SpecType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PreDie = pd.get_dummies(X.iloc[:, 2], drop_first = True, prefix = 'PreDie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PreDie_Y\n",
      "0           1\n",
      "1           0\n",
      "2           1\n",
      "3           1\n",
      "4           1\n",
      "..        ...\n",
      "352         1\n",
      "353         0\n",
      "354         0\n",
      "355         1\n",
      "356         1\n",
      "\n",
      "[357 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 이전에 질병없었던 환자들은 제거하고 출력함\n",
    "\n",
    "print(PreDie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  PreviousSurgery  Smoker  Homeless  DaysinHospital\n",
      "0     33                0       1         0               1\n",
      "1     34                0       1         0              22\n",
      "2     88                1       1         1             100\n",
      "3     56                0       1         0               2\n",
      "4     45                0       1         0              34\n",
      "..   ...              ...     ...       ...             ...\n",
      "352   14                1       1         1               2\n",
      "353   45                0       1         1               2\n",
      "354   67                1       1         1               2\n",
      "355   43                1       0         1               2\n",
      "356    2                1       0         1               2\n",
      "\n",
      "[357 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 인코딩해줬던 원래 변수 제거하고,\n",
    "# 별로 필요없을 것이라고 생각되는 성별 변수도 제거\n",
    "\n",
    "X.drop(['Admission_type', 'PreExistingDisease', 'Gender'], axis = 1, inplace = True)\n",
    "print(X)\n",
    "\n",
    "# axis = 1\n",
    "# inplace : 실제 메모리상에는 올라가있는데 데이터에도 적용해줘라."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat(\n",
    "    [X,SpecType, PreDie], axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  PreviousSurgery  Smoker  Homeless  DaysinHospital  \\\n",
      "0     33                0       1         0               1   \n",
      "1     34                0       1         0              22   \n",
      "2     88                1       1         1             100   \n",
      "3     56                0       1         0               2   \n",
      "4     45                0       1         0              34   \n",
      "..   ...              ...     ...       ...             ...   \n",
      "352   14                1       1         1               2   \n",
      "353   45                0       1         1               2   \n",
      "354   67                1       1         1               2   \n",
      "355   43                1       0         1               2   \n",
      "356    2                1       0         1               2   \n",
      "\n",
      "     SpecType_Emergency  SpecType_Newborn  SpecType_Trauma  SpecType_Urgent  \\\n",
      "0                     0                 0                0                1   \n",
      "1                     1                 0                0                0   \n",
      "2                     0                 0                1                0   \n",
      "3                     0                 0                0                0   \n",
      "4                     0                 0                1                0   \n",
      "..                  ...               ...              ...              ...   \n",
      "352                   0                 0                1                0   \n",
      "353                   0                 0                1                0   \n",
      "354                   0                 0                1                0   \n",
      "355                   0                 0                1                0   \n",
      "356                   0                 0                1                0   \n",
      "\n",
      "     PreDie_Y  \n",
      "0           1  \n",
      "1           0  \n",
      "2           1  \n",
      "3           1  \n",
      "4           1  \n",
      "..        ...  \n",
      "352         1  \n",
      "353         0  \n",
      "354         0  \n",
      "355         1  \n",
      "356         1  \n",
      "\n",
      "[357 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 훈련시키고 test해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.3, random_state = 1 # 재현율때문에 110했는데, 구지 ㅁ~~\n",
    ")\n",
    "\n",
    "# 이걸 돌릴때마다 재현율은 달라짐~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 10)\n",
      "(249,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)  # 일반 벡터형태로 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 10)\n",
      "(108,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3025210084033613\n",
      "0.6974789915966386\n"
     ]
    }
   ],
   "source": [
    "print(108 / 357)\n",
    "print(249 / 357)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  PreviousSurgery  Smoker  Homeless  DaysinHospital  \\\n",
      "62    23                1       1         0              56   \n",
      "154    6                0       1         1              77   \n",
      "185   44                0       0         0              74   \n",
      "102   88                0       1         1               3   \n",
      "207   91                0       1         1              99   \n",
      "..   ...              ...     ...       ...             ...   \n",
      "203   91                1       1         0              96   \n",
      "255   35                1       1         1              25   \n",
      "72    48                0       0         0              14   \n",
      "235   91                0       1         1             123   \n",
      "37    77                0       1         0              44   \n",
      "\n",
      "     SpecType_Emergency  SpecType_Newborn  SpecType_Trauma  SpecType_Urgent  \\\n",
      "62                    0                 0                1                0   \n",
      "154                   0                 0                0                1   \n",
      "185                   1                 0                0                0   \n",
      "102                   0                 0                1                0   \n",
      "207                   0                 0                1                0   \n",
      "..                  ...               ...              ...              ...   \n",
      "203                   0                 0                1                0   \n",
      "255                   0                 0                0                1   \n",
      "72                    0                 0                0                0   \n",
      "235                   0                 0                0                1   \n",
      "37                    0                 0                0                1   \n",
      "\n",
      "     PreDie_Y  \n",
      "62          0  \n",
      "154         0  \n",
      "185         0  \n",
      "102         0  \n",
      "207         1  \n",
      "..        ...  \n",
      "203         1  \n",
      "255         0  \n",
      "72          0  \n",
      "235         1  \n",
      "37          0  \n",
      "\n",
      "[249 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.63137586  1.30633906  0.85391256 ...  1.94639707 -0.78541907\n",
      "  -0.75891328]\n",
      " [-1.20477514 -0.76549805  0.85391256 ... -0.51376978  1.27320565\n",
      "  -0.75891328]\n",
      " [ 0.07694089 -0.76549805 -1.17108009 ... -0.51376978 -0.78541907\n",
      "  -0.75891328]\n",
      " ...\n",
      " [ 0.21185837 -0.76549805 -1.17108009 ... -0.51376978 -0.78541907\n",
      "  -0.75891328]\n",
      " [ 1.66222125 -0.76549805  0.85391256 ... -0.51376978  1.27320565\n",
      "   1.31767361]\n",
      " [ 1.19001008 -0.76549805  0.85391256 ... -0.51376978  1.27320565\n",
      "  -0.75891328]]\n"
     ]
    }
   ],
   "source": [
    "# 다시\n",
    "# 인코딩되어있는 데이터를 정규분포로 ~~\n",
    "\n",
    "# Z 스코어 베이스의 scaling을 한 것!\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Age  PreviousSurgery    Smoker  Homeless  DaysinHospital  \\\n",
      "0   -0.631376         1.306339  0.853913 -0.745822        0.288742   \n",
      "1   -1.204775        -0.765498  0.853913  1.340803        0.739842   \n",
      "2    0.076941        -0.765498 -1.171080 -0.745822        0.675399   \n",
      "3    1.561033        -0.765498  0.853913  1.340803       -0.849748   \n",
      "4    1.662221        -0.765498  0.853913  1.340803        1.212423   \n",
      "..        ...              ...       ...       ...             ...   \n",
      "244  1.662221         1.306339  0.853913 -0.745822        1.147980   \n",
      "245 -0.226623         1.306339  0.853913  1.340803       -0.377168   \n",
      "246  0.211858        -0.765498 -1.171080 -0.745822       -0.613458   \n",
      "247  1.662221        -0.765498  0.853913  1.340803        1.727966   \n",
      "248  1.190010        -0.765498  0.853913 -0.745822        0.030971   \n",
      "\n",
      "     SpecType_Emergency  SpecType_Newborn  SpecType_Trauma  SpecType_Urgent  \\\n",
      "0             -0.341456         -0.295527         1.946397        -0.785419   \n",
      "1             -0.341456         -0.295527        -0.513770         1.273206   \n",
      "2              2.928638         -0.295527        -0.513770        -0.785419   \n",
      "3             -0.341456         -0.295527         1.946397        -0.785419   \n",
      "4             -0.341456         -0.295527         1.946397        -0.785419   \n",
      "..                  ...               ...              ...              ...   \n",
      "244           -0.341456         -0.295527         1.946397        -0.785419   \n",
      "245           -0.341456         -0.295527        -0.513770         1.273206   \n",
      "246           -0.341456         -0.295527        -0.513770        -0.785419   \n",
      "247           -0.341456         -0.295527        -0.513770         1.273206   \n",
      "248           -0.341456         -0.295527        -0.513770         1.273206   \n",
      "\n",
      "     PreDie_Y  \n",
      "0   -0.758913  \n",
      "1   -0.758913  \n",
      "2   -0.758913  \n",
      "3   -0.758913  \n",
      "4    1.317674  \n",
      "..        ...  \n",
      "244  1.317674  \n",
      "245 -0.758913  \n",
      "246 -0.758913  \n",
      "247  1.317674  \n",
      "248 -0.758913  \n",
      "\n",
      "[249 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train, columns = X_test.columns)\n",
    "\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>PreviousSurgery</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Homeless</th>\n",
       "      <th>DaysinHospital</th>\n",
       "      <th>SpecType_Emergency</th>\n",
       "      <th>SpecType_Newborn</th>\n",
       "      <th>SpecType_Trauma</th>\n",
       "      <th>SpecType_Urgent</th>\n",
       "      <th>PreDie_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.631376</td>\n",
       "      <td>1.306339</td>\n",
       "      <td>0.853913</td>\n",
       "      <td>-0.745822</td>\n",
       "      <td>0.288742</td>\n",
       "      <td>-0.341456</td>\n",
       "      <td>-0.295527</td>\n",
       "      <td>1.946397</td>\n",
       "      <td>-0.785419</td>\n",
       "      <td>-0.758913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.204775</td>\n",
       "      <td>-0.765498</td>\n",
       "      <td>0.853913</td>\n",
       "      <td>1.340803</td>\n",
       "      <td>0.739842</td>\n",
       "      <td>-0.341456</td>\n",
       "      <td>-0.295527</td>\n",
       "      <td>-0.513770</td>\n",
       "      <td>1.273206</td>\n",
       "      <td>-0.758913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076941</td>\n",
       "      <td>-0.765498</td>\n",
       "      <td>-1.171080</td>\n",
       "      <td>-0.745822</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>2.928638</td>\n",
       "      <td>-0.295527</td>\n",
       "      <td>-0.513770</td>\n",
       "      <td>-0.785419</td>\n",
       "      <td>-0.758913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.561033</td>\n",
       "      <td>-0.765498</td>\n",
       "      <td>0.853913</td>\n",
       "      <td>1.340803</td>\n",
       "      <td>-0.849748</td>\n",
       "      <td>-0.341456</td>\n",
       "      <td>-0.295527</td>\n",
       "      <td>1.946397</td>\n",
       "      <td>-0.785419</td>\n",
       "      <td>-0.758913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.662221</td>\n",
       "      <td>-0.765498</td>\n",
       "      <td>0.853913</td>\n",
       "      <td>1.340803</td>\n",
       "      <td>1.212423</td>\n",
       "      <td>-0.341456</td>\n",
       "      <td>-0.295527</td>\n",
       "      <td>1.946397</td>\n",
       "      <td>-0.785419</td>\n",
       "      <td>1.317674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  PreviousSurgery    Smoker  Homeless  DaysinHospital  \\\n",
       "0 -0.631376         1.306339  0.853913 -0.745822        0.288742   \n",
       "1 -1.204775        -0.765498  0.853913  1.340803        0.739842   \n",
       "2  0.076941        -0.765498 -1.171080 -0.745822        0.675399   \n",
       "3  1.561033        -0.765498  0.853913  1.340803       -0.849748   \n",
       "4  1.662221        -0.765498  0.853913  1.340803        1.212423   \n",
       "\n",
       "   SpecType_Emergency  SpecType_Newborn  SpecType_Trauma  SpecType_Urgent  \\\n",
       "0           -0.341456         -0.295527         1.946397        -0.785419   \n",
       "1           -0.341456         -0.295527        -0.513770         1.273206   \n",
       "2            2.928638         -0.295527        -0.513770        -0.785419   \n",
       "3           -0.341456         -0.295527         1.946397        -0.785419   \n",
       "4           -0.341456         -0.295527         1.946397        -0.785419   \n",
       "\n",
       "   PreDie_Y  \n",
       "0 -0.758913  \n",
       "1 -0.758913  \n",
       "2 -0.758913  \n",
       "3 -0.758913  \n",
       "4  1.317674  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명 다시~\n",
    "# numpy 버전으로 바꾸기\n",
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_np))\n",
    "\n",
    "# 수치해석 전용 다시~~\n",
    "# 데이터 10만개 이하부터는 numpy가 느림.\n",
    "# 데이터 10만개 이상부터는 numpy가 빨라짐.\n",
    "# numpy는 수치연산하는 C++ 기반임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(\n",
    "        # units 표현 안하고 숫자만 넣어도 됨 (원래는 그냥 숫자만 넣었음)\n",
    "        units = 6, activation = 'relu',\n",
    "        kernel_initializer = 'uniform',\n",
    "        input_dim = 10\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(Dropout(rate = 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(\n",
    "        units = 6, activation = 'relu',\n",
    "        kernel_initializer = 'uniform',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(\n",
    "        units = 12, activation = 'tanh',\n",
    "        kernel_initializer = 'uniform',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(\n",
    "        units = 6, activation = 'tanh',\n",
    "        kernel_initializer = 'uniform',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(\n",
    "        units = 1, activation = 'sigmoid',\n",
    "        kernel_initializer = 'uniform',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.8072\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.8072\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 607us/step - loss: 0.6781 - accuracy: 0.8072\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 591us/step - loss: 0.6669 - accuracy: 0.8072\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 586us/step - loss: 0.6503 - accuracy: 0.8072\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 588us/step - loss: 0.6241 - accuracy: 0.8072\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 608us/step - loss: 0.5883 - accuracy: 0.8072\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 554us/step - loss: 0.5472 - accuracy: 0.8072\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 594us/step - loss: 0.5124 - accuracy: 0.8072\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 554us/step - loss: 0.4818 - accuracy: 0.8072\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 823us/step - loss: 0.4685 - accuracy: 0.8072\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 563us/step - loss: 0.4547 - accuracy: 0.8072\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 559us/step - loss: 0.4496 - accuracy: 0.8072\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 695us/step - loss: 0.4450 - accuracy: 0.8072\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.4405 - accuracy: 0.8072\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.4210 - accuracy: 0.8072\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 583us/step - loss: 0.4239 - accuracy: 0.8072\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 562us/step - loss: 0.4179 - accuracy: 0.8072\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.4068 - accuracy: 0.8072\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 568us/step - loss: 0.3953 - accuracy: 0.8072\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 599us/step - loss: 0.3903 - accuracy: 0.8072\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 535us/step - loss: 0.3770 - accuracy: 0.8072\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.3653 - accuracy: 0.8072\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.3635 - accuracy: 0.8072\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 661us/step - loss: 0.3531 - accuracy: 0.8072\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 610us/step - loss: 0.3402 - accuracy: 0.8273\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.3328 - accuracy: 0.8715\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 592us/step - loss: 0.3239 - accuracy: 0.8755\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.3200 - accuracy: 0.8554\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 639us/step - loss: 0.2992 - accuracy: 0.8996\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 893us/step - loss: 0.2972 - accuracy: 0.8996\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 536us/step - loss: 0.2933 - accuracy: 0.9116\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 615us/step - loss: 0.2855 - accuracy: 0.9076\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 639us/step - loss: 0.2871 - accuracy: 0.9076\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 563us/step - loss: 0.2656 - accuracy: 0.9116\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 534us/step - loss: 0.2868 - accuracy: 0.8916\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 559us/step - loss: 0.2816 - accuracy: 0.9036\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 598us/step - loss: 0.2700 - accuracy: 0.9116\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 556us/step - loss: 0.2834 - accuracy: 0.8956\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 586us/step - loss: 0.2720 - accuracy: 0.9076\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 543us/step - loss: 0.2410 - accuracy: 0.9237\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 576us/step - loss: 0.2670 - accuracy: 0.8996\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 515us/step - loss: 0.2635 - accuracy: 0.9116\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 585us/step - loss: 0.2499 - accuracy: 0.9116\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 550us/step - loss: 0.2487 - accuracy: 0.9237\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 690us/step - loss: 0.2629 - accuracy: 0.9116\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 593us/step - loss: 0.2539 - accuracy: 0.9076\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 660us/step - loss: 0.2485 - accuracy: 0.9076\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 633us/step - loss: 0.2517 - accuracy: 0.9116\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 611us/step - loss: 0.2557 - accuracy: 0.9157\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2603 - accuracy: 0.9076\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 632us/step - loss: 0.2600 - accuracy: 0.8956\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 556us/step - loss: 0.2508 - accuracy: 0.9157\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2430 - accuracy: 0.9157\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2476 - accuracy: 0.9157\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.2465 - accuracy: 0.9116\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 551us/step - loss: 0.2514 - accuracy: 0.9237\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 581us/step - loss: 0.2352 - accuracy: 0.9197\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 581us/step - loss: 0.2622 - accuracy: 0.9036\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 530us/step - loss: 0.2501 - accuracy: 0.9116\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.2507 - accuracy: 0.9116\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 528us/step - loss: 0.2555 - accuracy: 0.9036\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2479 - accuracy: 0.9197\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 533us/step - loss: 0.2429 - accuracy: 0.9277\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 629us/step - loss: 0.2174 - accuracy: 0.9237\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 563us/step - loss: 0.2453 - accuracy: 0.9157\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.2305 - accuracy: 0.9197\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 513us/step - loss: 0.2382 - accuracy: 0.9157\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 550us/step - loss: 0.2440 - accuracy: 0.9076\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 621us/step - loss: 0.2316 - accuracy: 0.9197\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 556us/step - loss: 0.2453 - accuracy: 0.9116\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 568us/step - loss: 0.2353 - accuracy: 0.9237\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 540us/step - loss: 0.2517 - accuracy: 0.9116\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 539us/step - loss: 0.2361 - accuracy: 0.9116\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 534us/step - loss: 0.2457 - accuracy: 0.9237\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 600us/step - loss: 0.2303 - accuracy: 0.9237\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.2506 - accuracy: 0.9116\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.2467 - accuracy: 0.9157\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 516us/step - loss: 0.2325 - accuracy: 0.9197\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2421 - accuracy: 0.9116\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 618us/step - loss: 0.2641 - accuracy: 0.9036\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 517us/step - loss: 0.2458 - accuracy: 0.9157\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 568us/step - loss: 0.2353 - accuracy: 0.9197\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 543us/step - loss: 0.2329 - accuracy: 0.9197\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 605us/step - loss: 0.2466 - accuracy: 0.9157\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.2302 - accuracy: 0.9197\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 618us/step - loss: 0.2544 - accuracy: 0.9036\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2422 - accuracy: 0.9116\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 519us/step - loss: 0.2244 - accuracy: 0.9157\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.2543 - accuracy: 0.9076\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 539us/step - loss: 0.2251 - accuracy: 0.9277\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 598us/step - loss: 0.2545 - accuracy: 0.9157\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2222 - accuracy: 0.9317\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.2460 - accuracy: 0.9157\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 604us/step - loss: 0.2319 - accuracy: 0.9237\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 549us/step - loss: 0.2382 - accuracy: 0.9277\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 545us/step - loss: 0.2315 - accuracy: 0.9197\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.2443 - accuracy: 0.9157\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.2328 - accuracy: 0.9157\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 545us/step - loss: 0.2317 - accuracy: 0.9157\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.2725 - accuracy: 0.9036\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 536us/step - loss: 0.2409 - accuracy: 0.9197\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 574us/step - loss: 0.2417 - accuracy: 0.9237\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 528us/step - loss: 0.2261 - accuracy: 0.9277\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 612us/step - loss: 0.2405 - accuracy: 0.9036\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 567us/step - loss: 0.2342 - accuracy: 0.9157\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.2237 - accuracy: 0.9277\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.2307 - accuracy: 0.9237\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 566us/step - loss: 0.2249 - accuracy: 0.9277\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.2430 - accuracy: 0.9036\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.2481 - accuracy: 0.8996\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 508us/step - loss: 0.2279 - accuracy: 0.9197\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 596us/step - loss: 0.2291 - accuracy: 0.9237\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 634us/step - loss: 0.2223 - accuracy: 0.9317\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2115 - accuracy: 0.9438\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 597us/step - loss: 0.2223 - accuracy: 0.9237\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 525us/step - loss: 0.2168 - accuracy: 0.9398\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 580us/step - loss: 0.2160 - accuracy: 0.9317\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 516us/step - loss: 0.2396 - accuracy: 0.9277\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 544us/step - loss: 0.2340 - accuracy: 0.9237\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 618us/step - loss: 0.2364 - accuracy: 0.9277\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.2206 - accuracy: 0.9317\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 592us/step - loss: 0.2153 - accuracy: 0.9398\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.2282 - accuracy: 0.9277\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 570us/step - loss: 0.2363 - accuracy: 0.9157\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 612us/step - loss: 0.2284 - accuracy: 0.9237\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 628us/step - loss: 0.2174 - accuracy: 0.9357\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 611us/step - loss: 0.2404 - accuracy: 0.9157\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 585us/step - loss: 0.2313 - accuracy: 0.9317\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 900us/step - loss: 0.2195 - accuracy: 0.9398\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 604us/step - loss: 0.2121 - accuracy: 0.9357\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.2315 - accuracy: 0.9237\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 598us/step - loss: 0.2196 - accuracy: 0.9317\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.2223 - accuracy: 0.9237\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 601us/step - loss: 0.2228 - accuracy: 0.9197\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 574us/step - loss: 0.2346 - accuracy: 0.9197\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 593us/step - loss: 0.2216 - accuracy: 0.9357\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 599us/step - loss: 0.2247 - accuracy: 0.9237\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.2336 - accuracy: 0.9277\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 633us/step - loss: 0.2178 - accuracy: 0.9277\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 694us/step - loss: 0.2256 - accuracy: 0.9357\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2146 - accuracy: 0.9317\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 630us/step - loss: 0.2373 - accuracy: 0.9157\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 569us/step - loss: 0.2336 - accuracy: 0.9197\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 620us/step - loss: 0.1887 - accuracy: 0.9478\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 563us/step - loss: 0.2354 - accuracy: 0.9237\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.2272 - accuracy: 0.9317\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 620us/step - loss: 0.2325 - accuracy: 0.9317\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 579us/step - loss: 0.2260 - accuracy: 0.9277\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 596us/step - loss: 0.2390 - accuracy: 0.9197\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 605us/step - loss: 0.2103 - accuracy: 0.9357\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 601us/step - loss: 0.2121 - accuracy: 0.9438\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 591us/step - loss: 0.2229 - accuracy: 0.9277\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 560us/step - loss: 0.2185 - accuracy: 0.9317\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 554us/step - loss: 0.2328 - accuracy: 0.9197\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2337 - accuracy: 0.9237\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.2150 - accuracy: 0.9398\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 548us/step - loss: 0.2062 - accuracy: 0.9398\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 686us/step - loss: 0.2363 - accuracy: 0.9237\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 621us/step - loss: 0.2131 - accuracy: 0.9398\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 619us/step - loss: 0.2246 - accuracy: 0.9317\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 643us/step - loss: 0.2192 - accuracy: 0.9438\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.2313 - accuracy: 0.9277\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 674us/step - loss: 0.2132 - accuracy: 0.9438\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 609us/step - loss: 0.2341 - accuracy: 0.9237\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.2373 - accuracy: 0.9277\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 586us/step - loss: 0.2142 - accuracy: 0.9357\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.2224 - accuracy: 0.9357\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 618us/step - loss: 0.2229 - accuracy: 0.9317\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 567us/step - loss: 0.2081 - accuracy: 0.9357\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 739us/step - loss: 0.2263 - accuracy: 0.9357\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 593us/step - loss: 0.2208 - accuracy: 0.9317\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 583us/step - loss: 0.2419 - accuracy: 0.9157\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 615us/step - loss: 0.2128 - accuracy: 0.9317\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 535us/step - loss: 0.2227 - accuracy: 0.9317\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 610us/step - loss: 0.2064 - accuracy: 0.9398\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 600us/step - loss: 0.2345 - accuracy: 0.9197\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 586us/step - loss: 0.2245 - accuracy: 0.9277\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 638us/step - loss: 0.2269 - accuracy: 0.9277\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 548us/step - loss: 0.2197 - accuracy: 0.9357\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 600us/step - loss: 0.2069 - accuracy: 0.9277\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 580us/step - loss: 0.2199 - accuracy: 0.9317\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 580us/step - loss: 0.1917 - accuracy: 0.9357\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 624us/step - loss: 0.2180 - accuracy: 0.9317\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2223 - accuracy: 0.9357\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.2177 - accuracy: 0.9277\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 557us/step - loss: 0.2195 - accuracy: 0.9357\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 636us/step - loss: 0.2124 - accuracy: 0.9357\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.2258 - accuracy: 0.9317\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 597us/step - loss: 0.2123 - accuracy: 0.9438\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 850us/step - loss: 0.2097 - accuracy: 0.9277\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 563us/step - loss: 0.2214 - accuracy: 0.9317\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 606us/step - loss: 0.2131 - accuracy: 0.9398\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2209 - accuracy: 0.9277\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 597us/step - loss: 0.2264 - accuracy: 0.9357\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 566us/step - loss: 0.2327 - accuracy: 0.9237\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 591us/step - loss: 0.2247 - accuracy: 0.9317\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 1.00 - 0s 589us/step - loss: 0.2257 - accuracy: 0.9357\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 574us/step - loss: 0.2084 - accuracy: 0.9357\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 698us/step - loss: 0.2219 - accuracy: 0.9317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf94509c50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_np, y_train_np, \n",
    "    epochs = 200, \n",
    "    # 계산할 때 몇개 단위로 계산할 것인가\n",
    "    batch_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "13/13 [==============================] - 0s 580us/step - loss: 0.2186 - accuracy: 0.9317\n",
      "Epoch 2/400\n",
      "13/13 [==============================] - 0s 587us/step - loss: 0.2277 - accuracy: 0.9277\n",
      "Epoch 3/400\n",
      "13/13 [==============================] - 0s 601us/step - loss: 0.2156 - accuracy: 0.9357\n",
      "Epoch 4/400\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2219 - accuracy: 0.9317\n",
      "Epoch 5/400\n",
      "13/13 [==============================] - 0s 642us/step - loss: 0.2144 - accuracy: 0.9277\n",
      "Epoch 6/400\n",
      "13/13 [==============================] - 0s 519us/step - loss: 0.2111 - accuracy: 0.9398\n",
      "Epoch 7/400\n",
      "13/13 [==============================] - 0s 521us/step - loss: 0.2083 - accuracy: 0.9398\n",
      "Epoch 8/400\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.2115 - accuracy: 0.9317\n",
      "Epoch 9/400\n",
      "13/13 [==============================] - 0s 595us/step - loss: 0.2101 - accuracy: 0.9357\n",
      "Epoch 10/400\n",
      "13/13 [==============================] - 0s 637us/step - loss: 0.1967 - accuracy: 0.9438\n",
      "Epoch 11/400\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.1952 - accuracy: 0.9357\n",
      "Epoch 12/400\n",
      "13/13 [==============================] - 0s 523us/step - loss: 0.2378 - accuracy: 0.9317\n",
      "Epoch 13/400\n",
      "13/13 [==============================] - 0s 519us/step - loss: 0.2204 - accuracy: 0.9357\n",
      "Epoch 14/400\n",
      "13/13 [==============================] - 0s 600us/step - loss: 0.1966 - accuracy: 0.9438\n",
      "Epoch 15/400\n",
      "13/13 [==============================] - 0s 567us/step - loss: 0.2085 - accuracy: 0.9357\n",
      "Epoch 16/400\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.2203 - accuracy: 0.9357\n",
      "Epoch 17/400\n",
      "13/13 [==============================] - 0s 577us/step - loss: 0.2411 - accuracy: 0.9116\n",
      "Epoch 18/400\n",
      "13/13 [==============================] - 0s 544us/step - loss: 0.1970 - accuracy: 0.9438\n",
      "Epoch 19/400\n",
      "13/13 [==============================] - 0s 577us/step - loss: 0.2209 - accuracy: 0.9277\n",
      "Epoch 20/400\n",
      "13/13 [==============================] - 0s 620us/step - loss: 0.2058 - accuracy: 0.9317\n",
      "Epoch 21/400\n",
      "13/13 [==============================] - 0s 577us/step - loss: 0.2560 - accuracy: 0.9076\n",
      "Epoch 22/400\n",
      "13/13 [==============================] - 0s 597us/step - loss: 0.2125 - accuracy: 0.9317\n",
      "Epoch 23/400\n",
      "13/13 [==============================] - 0s 636us/step - loss: 0.2007 - accuracy: 0.9438\n",
      "Epoch 24/400\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.2133 - accuracy: 0.9398\n",
      "Epoch 25/400\n",
      "13/13 [==============================] - 0s 562us/step - loss: 0.2132 - accuracy: 0.9317\n",
      "Epoch 26/400\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.2236 - accuracy: 0.9357\n",
      "Epoch 27/400\n",
      "13/13 [==============================] - 0s 546us/step - loss: 0.2047 - accuracy: 0.9398\n",
      "Epoch 28/400\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.2063 - accuracy: 0.9398\n",
      "Epoch 29/400\n",
      "13/13 [==============================] - 0s 606us/step - loss: 0.2166 - accuracy: 0.9317\n",
      "Epoch 30/400\n",
      "13/13 [==============================] - 0s 564us/step - loss: 0.2343 - accuracy: 0.9237\n",
      "Epoch 31/400\n",
      "13/13 [==============================] - 0s 637us/step - loss: 0.2306 - accuracy: 0.9197\n",
      "Epoch 32/400\n",
      "13/13 [==============================] - 0s 652us/step - loss: 0.2270 - accuracy: 0.9357\n",
      "Epoch 33/400\n",
      "13/13 [==============================] - 0s 566us/step - loss: 0.2180 - accuracy: 0.9357\n",
      "Epoch 34/400\n",
      "13/13 [==============================] - 0s 600us/step - loss: 0.2207 - accuracy: 0.9357\n",
      "Epoch 35/400\n",
      "13/13 [==============================] - 0s 602us/step - loss: 0.2112 - accuracy: 0.9357\n",
      "Epoch 36/400\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.1984 - accuracy: 0.9438\n",
      "Epoch 37/400\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2069 - accuracy: 0.9398\n",
      "Epoch 38/400\n",
      "13/13 [==============================] - 0s 523us/step - loss: 0.2141 - accuracy: 0.9357\n",
      "Epoch 39/400\n",
      "13/13 [==============================] - 0s 570us/step - loss: 0.2146 - accuracy: 0.9398\n",
      "Epoch 40/400\n",
      "13/13 [==============================] - 0s 544us/step - loss: 0.2332 - accuracy: 0.9237\n",
      "Epoch 41/400\n",
      "13/13 [==============================] - 0s 672us/step - loss: 0.2031 - accuracy: 0.9438\n",
      "Epoch 42/400\n",
      "13/13 [==============================] - 0s 594us/step - loss: 0.2132 - accuracy: 0.9277\n",
      "Epoch 43/400\n",
      "13/13 [==============================] - 0s 608us/step - loss: 0.2243 - accuracy: 0.9317\n",
      "Epoch 44/400\n",
      "13/13 [==============================] - 0s 574us/step - loss: 0.2326 - accuracy: 0.9277\n",
      "Epoch 45/400\n",
      "13/13 [==============================] - 0s 530us/step - loss: 0.2092 - accuracy: 0.9317\n",
      "Epoch 46/400\n",
      "13/13 [==============================] - 0s 599us/step - loss: 0.2301 - accuracy: 0.9237\n",
      "Epoch 47/400\n",
      "13/13 [==============================] - 0s 535us/step - loss: 0.2145 - accuracy: 0.9357\n",
      "Epoch 48/400\n",
      "13/13 [==============================] - 0s 601us/step - loss: 0.2124 - accuracy: 0.9317\n",
      "Epoch 49/400\n",
      "13/13 [==============================] - 0s 581us/step - loss: 0.2181 - accuracy: 0.9357\n",
      "Epoch 50/400\n",
      "13/13 [==============================] - 0s 608us/step - loss: 0.2324 - accuracy: 0.9237\n",
      "Epoch 51/400\n",
      "13/13 [==============================] - 0s 560us/step - loss: 0.2053 - accuracy: 0.9357\n",
      "Epoch 52/400\n",
      "13/13 [==============================] - 0s 536us/step - loss: 0.1993 - accuracy: 0.9357\n",
      "Epoch 53/400\n",
      "13/13 [==============================] - 0s 618us/step - loss: 0.2386 - accuracy: 0.9197\n",
      "Epoch 54/400\n",
      "13/13 [==============================] - 0s 568us/step - loss: 0.2069 - accuracy: 0.9398\n",
      "Epoch 55/400\n",
      "13/13 [==============================] - 0s 589us/step - loss: 0.2068 - accuracy: 0.9357\n",
      "Epoch 56/400\n",
      "13/13 [==============================] - 0s 599us/step - loss: 0.2191 - accuracy: 0.9317\n",
      "Epoch 57/400\n",
      "13/13 [==============================] - 0s 512us/step - loss: 0.2129 - accuracy: 0.9317\n",
      "Epoch 58/400\n",
      "13/13 [==============================] - 0s 569us/step - loss: 0.2168 - accuracy: 0.9317\n",
      "Epoch 59/400\n",
      "13/13 [==============================] - 0s 526us/step - loss: 0.2265 - accuracy: 0.9317\n",
      "Epoch 60/400\n",
      "13/13 [==============================] - 0s 579us/step - loss: 0.2079 - accuracy: 0.9317\n",
      "Epoch 61/400\n",
      "13/13 [==============================] - 0s 604us/step - loss: 0.2167 - accuracy: 0.9277\n",
      "Epoch 62/400\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.1952 - accuracy: 0.9438\n",
      "Epoch 63/400\n",
      "13/13 [==============================] - 0s 557us/step - loss: 0.2153 - accuracy: 0.9277\n",
      "Epoch 64/400\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.1992 - accuracy: 0.9398\n",
      "Epoch 65/400\n",
      "13/13 [==============================] - 0s 558us/step - loss: 0.2194 - accuracy: 0.9277\n",
      "Epoch 66/400\n",
      "13/13 [==============================] - 0s 527us/step - loss: 0.1951 - accuracy: 0.9438\n",
      "Epoch 67/400\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.2034 - accuracy: 0.9398\n",
      "Epoch 68/400\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.2160 - accuracy: 0.9197\n",
      "Epoch 69/400\n",
      "13/13 [==============================] - 0s 574us/step - loss: 0.1920 - accuracy: 0.9357\n",
      "Epoch 70/400\n",
      "13/13 [==============================] - 0s 612us/step - loss: 0.2268 - accuracy: 0.9277\n",
      "Epoch 71/400\n",
      "13/13 [==============================] - 0s 611us/step - loss: 0.2166 - accuracy: 0.9317\n",
      "Epoch 72/400\n",
      "13/13 [==============================] - 0s 605us/step - loss: 0.2185 - accuracy: 0.9317\n",
      "Epoch 73/400\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.1930 - accuracy: 0.9438\n",
      "Epoch 74/400\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.2180 - accuracy: 0.9317\n",
      "Epoch 75/400\n",
      "13/13 [==============================] - 0s 550us/step - loss: 0.2213 - accuracy: 0.9197\n",
      "Epoch 76/400\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.2182 - accuracy: 0.9277\n",
      "Epoch 77/400\n",
      "13/13 [==============================] - 0s 556us/step - loss: 0.2015 - accuracy: 0.9398\n",
      "Epoch 78/400\n",
      "13/13 [==============================] - 0s 617us/step - loss: 0.2163 - accuracy: 0.9317\n",
      "Epoch 79/400\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.9357\n",
      "Epoch 80/400\n",
      "13/13 [==============================] - 0s 612us/step - loss: 0.2011 - accuracy: 0.9398\n",
      "Epoch 81/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 608us/step - loss: 0.2106 - accuracy: 0.9277\n",
      "Epoch 82/400\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.2122 - accuracy: 0.9357\n",
      "Epoch 83/400\n",
      "13/13 [==============================] - 0s 666us/step - loss: 0.2062 - accuracy: 0.9398\n",
      "Epoch 84/400\n",
      "13/13 [==============================] - 0s 610us/step - loss: 0.1999 - accuracy: 0.9438\n",
      "Epoch 85/400\n",
      "13/13 [==============================] - 0s 581us/step - loss: 0.2140 - accuracy: 0.9277\n",
      "Epoch 86/400\n",
      "13/13 [==============================] - 0s 593us/step - loss: 0.2041 - accuracy: 0.9357\n",
      "Epoch 87/400\n",
      "13/13 [==============================] - 0s 582us/step - loss: 0.2028 - accuracy: 0.9357\n",
      "Epoch 88/400\n",
      "13/13 [==============================] - 0s 700us/step - loss: 0.2112 - accuracy: 0.9398\n",
      "Epoch 89/400\n",
      "13/13 [==============================] - 0s 665us/step - loss: 0.2146 - accuracy: 0.9277\n",
      "Epoch 90/400\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.2005 - accuracy: 0.9398\n",
      "Epoch 91/400\n",
      "13/13 [==============================] - 0s 656us/step - loss: 0.2070 - accuracy: 0.9398\n",
      "Epoch 92/400\n",
      "13/13 [==============================] - 0s 595us/step - loss: 0.2189 - accuracy: 0.9317\n",
      "Epoch 93/400\n",
      "13/13 [==============================] - 0s 733us/step - loss: 0.2094 - accuracy: 0.9317\n",
      "Epoch 94/400\n",
      "13/13 [==============================] - 0s 599us/step - loss: 0.2009 - accuracy: 0.9357\n",
      "Epoch 95/400\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.2098 - accuracy: 0.9398\n",
      "Epoch 96/400\n",
      "13/13 [==============================] - 0s 598us/step - loss: 0.2009 - accuracy: 0.9398\n",
      "Epoch 97/400\n",
      "13/13 [==============================] - 0s 526us/step - loss: 0.2028 - accuracy: 0.9398\n",
      "Epoch 98/400\n",
      "13/13 [==============================] - 0s 612us/step - loss: 0.2284 - accuracy: 0.9237\n",
      "Epoch 99/400\n",
      "13/13 [==============================] - 0s 590us/step - loss: 0.2048 - accuracy: 0.9357\n",
      "Epoch 100/400\n",
      "13/13 [==============================] - 0s 557us/step - loss: 0.2224 - accuracy: 0.9357\n",
      "Epoch 101/400\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.2194 - accuracy: 0.9277\n",
      "Epoch 102/400\n",
      "13/13 [==============================] - 0s 711us/step - loss: 0.1980 - accuracy: 0.9438\n",
      "Epoch 103/400\n",
      "13/13 [==============================] - 0s 524us/step - loss: 0.2333 - accuracy: 0.9157\n",
      "Epoch 104/400\n",
      "13/13 [==============================] - 0s 585us/step - loss: 0.1945 - accuracy: 0.9357\n",
      "Epoch 105/400\n",
      "13/13 [==============================] - 0s 618us/step - loss: 0.2207 - accuracy: 0.9277\n",
      "Epoch 106/400\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.1946 - accuracy: 0.9438\n",
      "Epoch 107/400\n",
      "13/13 [==============================] - 0s 622us/step - loss: 0.2330 - accuracy: 0.9197\n",
      "Epoch 108/400\n",
      "13/13 [==============================] - 0s 544us/step - loss: 0.2114 - accuracy: 0.9357\n",
      "Epoch 109/400\n",
      "13/13 [==============================] - 0s 621us/step - loss: 0.2110 - accuracy: 0.9357\n",
      "Epoch 110/400\n",
      "13/13 [==============================] - 0s 533us/step - loss: 0.2064 - accuracy: 0.9357\n",
      "Epoch 111/400\n",
      "13/13 [==============================] - 0s 569us/step - loss: 0.2032 - accuracy: 0.9438\n",
      "Epoch 112/400\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.2318 - accuracy: 0.9277\n",
      "Epoch 113/400\n",
      "13/13 [==============================] - 0s 557us/step - loss: 0.2006 - accuracy: 0.9357\n",
      "Epoch 114/400\n",
      "13/13 [==============================] - 0s 843us/step - loss: 0.2182 - accuracy: 0.9317\n",
      "Epoch 115/400\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2305 - accuracy: 0.9317\n",
      "Epoch 116/400\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.1902 - accuracy: 0.9478\n",
      "Epoch 117/400\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.1896 - accuracy: 0.9438\n",
      "Epoch 118/400\n",
      "13/13 [==============================] - 0s 584us/step - loss: 0.2162 - accuracy: 0.9277\n",
      "Epoch 119/400\n",
      "13/13 [==============================] - 0s 637us/step - loss: 0.2113 - accuracy: 0.9317\n",
      "Epoch 120/400\n",
      "13/13 [==============================] - 0s 540us/step - loss: 0.2122 - accuracy: 0.9438\n",
      "Epoch 121/400\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.2274 - accuracy: 0.9277\n",
      "Epoch 122/400\n",
      "13/13 [==============================] - 0s 533us/step - loss: 0.2027 - accuracy: 0.9398\n",
      "Epoch 123/400\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.1998 - accuracy: 0.9398\n",
      "Epoch 124/400\n",
      "13/13 [==============================] - 0s 533us/step - loss: 0.2060 - accuracy: 0.9357\n",
      "Epoch 125/400\n",
      "13/13 [==============================] - 0s 566us/step - loss: 0.2194 - accuracy: 0.9277\n",
      "Epoch 126/400\n",
      "13/13 [==============================] - 0s 549us/step - loss: 0.1992 - accuracy: 0.9438\n",
      "Epoch 127/400\n",
      "13/13 [==============================] - 0s 574us/step - loss: 0.2288 - accuracy: 0.9277\n",
      "Epoch 128/400\n",
      "13/13 [==============================] - 0s 531us/step - loss: 0.2105 - accuracy: 0.9357\n",
      "Epoch 129/400\n",
      "13/13 [==============================] - 0s 623us/step - loss: 0.1956 - accuracy: 0.9438\n",
      "Epoch 130/400\n",
      "13/13 [==============================] - 0s 566us/step - loss: 0.2200 - accuracy: 0.9317\n",
      "Epoch 131/400\n",
      "13/13 [==============================] - 0s 560us/step - loss: 0.2115 - accuracy: 0.9357\n",
      "Epoch 132/400\n",
      "13/13 [==============================] - 0s 559us/step - loss: 0.2048 - accuracy: 0.9398\n",
      "Epoch 133/400\n",
      "13/13 [==============================] - 0s 558us/step - loss: 0.2149 - accuracy: 0.9277\n",
      "Epoch 134/400\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.1969 - accuracy: 0.9357\n",
      "Epoch 135/400\n",
      "13/13 [==============================] - 0s 558us/step - loss: 0.2197 - accuracy: 0.9317\n",
      "Epoch 136/400\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2077 - accuracy: 0.9317\n",
      "Epoch 137/400\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.1872 - accuracy: 0.9438\n",
      "Epoch 138/400\n",
      "13/13 [==============================] - 0s 569us/step - loss: 0.2159 - accuracy: 0.9317\n",
      "Epoch 139/400\n",
      "13/13 [==============================] - 0s 563us/step - loss: 0.2274 - accuracy: 0.9277\n",
      "Epoch 140/400\n",
      "13/13 [==============================] - 0s 587us/step - loss: 0.1961 - accuracy: 0.9438\n",
      "Epoch 141/400\n",
      "13/13 [==============================] - 0s 526us/step - loss: 0.2170 - accuracy: 0.9317\n",
      "Epoch 142/400\n",
      "13/13 [==============================] - 0s 570us/step - loss: 0.2097 - accuracy: 0.9317\n",
      "Epoch 143/400\n",
      "13/13 [==============================] - 0s 556us/step - loss: 0.2112 - accuracy: 0.9357\n",
      "Epoch 144/400\n",
      "13/13 [==============================] - 0s 581us/step - loss: 0.2189 - accuracy: 0.9237\n",
      "Epoch 145/400\n",
      "13/13 [==============================] - 0s 641us/step - loss: 0.2112 - accuracy: 0.9357\n",
      "Epoch 146/400\n",
      "13/13 [==============================] - 0s 571us/step - loss: 0.2121 - accuracy: 0.9317\n",
      "Epoch 147/400\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.2275 - accuracy: 0.9277\n",
      "Epoch 148/400\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.2158 - accuracy: 0.9357\n",
      "Epoch 149/400\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.2247 - accuracy: 0.9237\n",
      "Epoch 150/400\n",
      "13/13 [==============================] - 0s 653us/step - loss: 0.2093 - accuracy: 0.9357\n",
      "Epoch 151/400\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.2144 - accuracy: 0.9277\n",
      "Epoch 152/400\n",
      "13/13 [==============================] - 0s 884us/step - loss: 0.2151 - accuracy: 0.9317\n",
      "Epoch 153/400\n",
      "13/13 [==============================] - 0s 566us/step - loss: 0.2331 - accuracy: 0.9157\n",
      "Epoch 154/400\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.2084 - accuracy: 0.9357\n",
      "Epoch 155/400\n",
      "13/13 [==============================] - 0s 550us/step - loss: 0.2059 - accuracy: 0.9398\n",
      "Epoch 156/400\n",
      "13/13 [==============================] - 0s 512us/step - loss: 0.2096 - accuracy: 0.9398\n",
      "Epoch 157/400\n",
      "13/13 [==============================] - 0s 534us/step - loss: 0.2020 - accuracy: 0.9438\n",
      "Epoch 158/400\n",
      "13/13 [==============================] - 0s 566us/step - loss: 0.1965 - accuracy: 0.9398\n",
      "Epoch 159/400\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.2190 - accuracy: 0.9277\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 670us/step - loss: 0.2135 - accuracy: 0.9317\n",
      "Epoch 161/400\n",
      "13/13 [==============================] - 0s 579us/step - loss: 0.2151 - accuracy: 0.9317\n",
      "Epoch 162/400\n",
      "13/13 [==============================] - 0s 551us/step - loss: 0.2093 - accuracy: 0.9317\n",
      "Epoch 163/400\n",
      "13/13 [==============================] - 0s 544us/step - loss: 0.2028 - accuracy: 0.9317\n",
      "Epoch 164/400\n",
      "13/13 [==============================] - 0s 543us/step - loss: 0.2075 - accuracy: 0.9398\n",
      "Epoch 165/400\n",
      "13/13 [==============================] - 0s 533us/step - loss: 0.1972 - accuracy: 0.9317\n",
      "Epoch 166/400\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.2208 - accuracy: 0.9277\n",
      "Epoch 167/400\n",
      "13/13 [==============================] - 0s 548us/step - loss: 0.2055 - accuracy: 0.9438\n",
      "Epoch 168/400\n",
      "13/13 [==============================] - 0s 533us/step - loss: 0.2040 - accuracy: 0.9398\n",
      "Epoch 169/400\n",
      "13/13 [==============================] - 0s 536us/step - loss: 0.2220 - accuracy: 0.9317\n",
      "Epoch 170/400\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.2032 - accuracy: 0.9357\n",
      "Epoch 171/400\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.1950 - accuracy: 0.9438\n",
      "Epoch 172/400\n",
      "13/13 [==============================] - 0s 569us/step - loss: 0.2019 - accuracy: 0.9398\n",
      "Epoch 173/400\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.1924 - accuracy: 0.9478\n",
      "Epoch 174/400\n",
      "13/13 [==============================] - 0s 580us/step - loss: 0.2054 - accuracy: 0.9438\n",
      "Epoch 175/400\n",
      "13/13 [==============================] - 0s 570us/step - loss: 0.2368 - accuracy: 0.9197\n",
      "Epoch 176/400\n",
      "13/13 [==============================] - 0s 572us/step - loss: 0.1894 - accuracy: 0.9438\n",
      "Epoch 177/400\n",
      "13/13 [==============================] - 0s 570us/step - loss: 0.1933 - accuracy: 0.9398\n",
      "Epoch 178/400\n",
      "13/13 [==============================] - 0s 550us/step - loss: 0.2063 - accuracy: 0.9357\n",
      "Epoch 179/400\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.2127 - accuracy: 0.9357\n",
      "Epoch 180/400\n",
      "13/13 [==============================] - 0s 554us/step - loss: 0.2047 - accuracy: 0.9398\n",
      "Epoch 181/400\n",
      "13/13 [==============================] - 0s 548us/step - loss: 0.2176 - accuracy: 0.9357\n",
      "Epoch 182/400\n",
      "13/13 [==============================] - 0s 523us/step - loss: 0.2320 - accuracy: 0.9197\n",
      "Epoch 183/400\n",
      "13/13 [==============================] - 0s 523us/step - loss: 0.2039 - accuracy: 0.9398\n",
      "Epoch 184/400\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.2120 - accuracy: 0.9237\n",
      "Epoch 185/400\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.2110 - accuracy: 0.9357\n",
      "Epoch 186/400\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.2256 - accuracy: 0.9277\n",
      "Epoch 187/400\n",
      "13/13 [==============================] - 0s 556us/step - loss: 0.2227 - accuracy: 0.9277\n",
      "Epoch 188/400\n",
      "13/13 [==============================] - 0s 557us/step - loss: 0.2075 - accuracy: 0.9398\n",
      "Epoch 189/400\n",
      "13/13 [==============================] - 0s 661us/step - loss: 0.1927 - accuracy: 0.9438\n",
      "Epoch 190/400\n",
      "13/13 [==============================] - 0s 549us/step - loss: 0.1962 - accuracy: 0.9357\n",
      "Epoch 191/400\n",
      "13/13 [==============================] - 0s 571us/step - loss: 0.1944 - accuracy: 0.9438\n",
      "Epoch 192/400\n",
      "13/13 [==============================] - 0s 541us/step - loss: 0.1954 - accuracy: 0.9357\n",
      "Epoch 193/400\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2050 - accuracy: 0.9438\n",
      "Epoch 194/400\n",
      "13/13 [==============================] - 0s 546us/step - loss: 0.2236 - accuracy: 0.9277\n",
      "Epoch 195/400\n",
      "13/13 [==============================] - 0s 557us/step - loss: 0.1984 - accuracy: 0.9438\n",
      "Epoch 196/400\n",
      "13/13 [==============================] - 0s 574us/step - loss: 0.2142 - accuracy: 0.9277\n",
      "Epoch 197/400\n",
      "13/13 [==============================] - 0s 582us/step - loss: 0.2206 - accuracy: 0.9197\n",
      "Epoch 198/400\n",
      "13/13 [==============================] - 0s 560us/step - loss: 0.2088 - accuracy: 0.9438\n",
      "Epoch 199/400\n",
      "13/13 [==============================] - 0s 679us/step - loss: 0.2152 - accuracy: 0.9317\n",
      "Epoch 200/400\n",
      "13/13 [==============================] - 0s 577us/step - loss: 0.2264 - accuracy: 0.9157\n",
      "Epoch 201/400\n",
      "13/13 [==============================] - 0s 546us/step - loss: 0.1931 - accuracy: 0.9478\n",
      "Epoch 202/400\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.2016 - accuracy: 0.9398\n",
      "Epoch 203/400\n",
      "13/13 [==============================] - 0s 526us/step - loss: 0.2050 - accuracy: 0.9357\n",
      "Epoch 204/400\n",
      "13/13 [==============================] - 0s 528us/step - loss: 0.1991 - accuracy: 0.9357\n",
      "Epoch 205/400\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.2280 - accuracy: 0.9237\n",
      "Epoch 206/400\n",
      "13/13 [==============================] - 0s 554us/step - loss: 0.2156 - accuracy: 0.9317\n",
      "Epoch 207/400\n",
      "13/13 [==============================] - 0s 594us/step - loss: 0.2077 - accuracy: 0.9357\n",
      "Epoch 208/400\n",
      "13/13 [==============================] - 0s 535us/step - loss: 0.1987 - accuracy: 0.9438\n",
      "Epoch 209/400\n",
      "13/13 [==============================] - 0s 703us/step - loss: 0.1912 - accuracy: 0.9398\n",
      "Epoch 210/400\n",
      "13/13 [==============================] - 0s 522us/step - loss: 0.1818 - accuracy: 0.9478\n",
      "Epoch 211/400\n",
      "13/13 [==============================] - 0s 549us/step - loss: 0.1900 - accuracy: 0.9478\n",
      "Epoch 212/400\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.1971 - accuracy: 0.9438\n",
      "Epoch 213/400\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.2144 - accuracy: 0.9398\n",
      "Epoch 214/400\n",
      "13/13 [==============================] - 0s 583us/step - loss: 0.2108 - accuracy: 0.9357\n",
      "Epoch 215/400\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.2144 - accuracy: 0.9237\n",
      "Epoch 216/400\n",
      "13/13 [==============================] - 0s 558us/step - loss: 0.2217 - accuracy: 0.9317\n",
      "Epoch 217/400\n",
      "13/13 [==============================] - 0s 528us/step - loss: 0.2224 - accuracy: 0.9357\n",
      "Epoch 218/400\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.1993 - accuracy: 0.9317\n",
      "Epoch 219/400\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.1889 - accuracy: 0.9398\n",
      "Epoch 220/400\n",
      "13/13 [==============================] - 0s 556us/step - loss: 0.2022 - accuracy: 0.9357\n",
      "Epoch 221/400\n",
      "13/13 [==============================] - 0s 587us/step - loss: 0.1972 - accuracy: 0.9438\n",
      "Epoch 222/400\n",
      "13/13 [==============================] - 0s 546us/step - loss: 0.2027 - accuracy: 0.9357\n",
      "Epoch 223/400\n",
      "13/13 [==============================] - 0s 567us/step - loss: 0.1991 - accuracy: 0.9398\n",
      "Epoch 224/400\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.1986 - accuracy: 0.9438\n",
      "Epoch 225/400\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.2033 - accuracy: 0.9398\n",
      "Epoch 226/400\n",
      "13/13 [==============================] - 0s 555us/step - loss: 0.1947 - accuracy: 0.9438\n",
      "Epoch 227/400\n",
      "13/13 [==============================] - 0s 559us/step - loss: 0.2125 - accuracy: 0.9398\n",
      "Epoch 228/400\n",
      "13/13 [==============================] - 0s 525us/step - loss: 0.2208 - accuracy: 0.9237\n",
      "Epoch 229/400\n",
      "13/13 [==============================] - 0s 616us/step - loss: 0.2052 - accuracy: 0.9357\n",
      "Epoch 230/400\n",
      "13/13 [==============================] - 0s 553us/step - loss: 0.2293 - accuracy: 0.9197\n",
      "Epoch 231/400\n",
      "13/13 [==============================] - 0s 577us/step - loss: 0.2179 - accuracy: 0.9317\n",
      "Epoch 232/400\n",
      "13/13 [==============================] - 0s 532us/step - loss: 0.1951 - accuracy: 0.9398\n",
      "Epoch 233/400\n",
      "13/13 [==============================] - 0s 595us/step - loss: 0.2273 - accuracy: 0.9277\n",
      "Epoch 234/400\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2150 - accuracy: 0.9277\n",
      "Epoch 235/400\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.2249 - accuracy: 0.9197\n",
      "Epoch 236/400\n",
      "13/13 [==============================] - 0s 524us/step - loss: 0.2193 - accuracy: 0.9237\n",
      "Epoch 237/400\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.2136 - accuracy: 0.9197\n",
      "Epoch 238/400\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.1966 - accuracy: 0.9398\n",
      "Epoch 239/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 597us/step - loss: 0.1966 - accuracy: 0.9357\n",
      "Epoch 240/400\n",
      "13/13 [==============================] - 0s 545us/step - loss: 0.2283 - accuracy: 0.9237\n",
      "Epoch 241/400\n",
      "13/13 [==============================] - 0s 548us/step - loss: 0.2195 - accuracy: 0.9277\n",
      "Epoch 242/400\n",
      "13/13 [==============================] - 0s 765us/step - loss: 0.2177 - accuracy: 0.9277\n",
      "Epoch 243/400\n",
      "13/13 [==============================] - 0s 562us/step - loss: 0.2032 - accuracy: 0.9357\n",
      "Epoch 244/400\n",
      "13/13 [==============================] - 0s 560us/step - loss: 0.2130 - accuracy: 0.9357\n",
      "Epoch 245/400\n",
      "13/13 [==============================] - 0s 627us/step - loss: 0.2135 - accuracy: 0.9237\n",
      "Epoch 246/400\n",
      "13/13 [==============================] - 0s 544us/step - loss: 0.2026 - accuracy: 0.9398\n",
      "Epoch 247/400\n",
      "13/13 [==============================] - 0s 829us/step - loss: 0.2199 - accuracy: 0.9277\n",
      "Epoch 248/400\n",
      "13/13 [==============================] - 0s 560us/step - loss: 0.2057 - accuracy: 0.9357\n",
      "Epoch 249/400\n",
      "13/13 [==============================] - 0s 605us/step - loss: 0.2333 - accuracy: 0.9197\n",
      "Epoch 250/400\n",
      "13/13 [==============================] - 0s 821us/step - loss: 0.2075 - accuracy: 0.9357\n",
      "Epoch 251/400\n",
      "13/13 [==============================] - 0s 549us/step - loss: 0.2124 - accuracy: 0.9357\n",
      "Epoch 252/400\n",
      "13/13 [==============================] - 0s 628us/step - loss: 0.2033 - accuracy: 0.9398\n",
      "Epoch 253/400\n",
      "13/13 [==============================] - 0s 571us/step - loss: 0.2215 - accuracy: 0.9317\n",
      "Epoch 254/400\n",
      "13/13 [==============================] - 0s 586us/step - loss: 0.2078 - accuracy: 0.9357\n",
      "Epoch 255/400\n",
      "13/13 [==============================] - 0s 529us/step - loss: 0.2248 - accuracy: 0.9237\n",
      "Epoch 256/400\n",
      "13/13 [==============================] - 0s 534us/step - loss: 0.2110 - accuracy: 0.9357\n",
      "Epoch 257/400\n",
      "13/13 [==============================] - 0s 635us/step - loss: 0.2192 - accuracy: 0.9357\n",
      "Epoch 258/400\n",
      "13/13 [==============================] - 0s 583us/step - loss: 0.2157 - accuracy: 0.9317\n",
      "Epoch 259/400\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.2200 - accuracy: 0.9317\n",
      "Epoch 260/400\n",
      "13/13 [==============================] - 0s 535us/step - loss: 0.1989 - accuracy: 0.9317\n",
      "Epoch 261/400\n",
      "13/13 [==============================] - 0s 582us/step - loss: 0.2126 - accuracy: 0.9317\n",
      "Epoch 262/400\n",
      "13/13 [==============================] - 0s 567us/step - loss: 0.2132 - accuracy: 0.9357\n",
      "Epoch 263/400\n",
      "13/13 [==============================] - 0s 550us/step - loss: 0.2304 - accuracy: 0.9237\n",
      "Epoch 264/400\n",
      "13/13 [==============================] - 0s 580us/step - loss: 0.2273 - accuracy: 0.9277\n",
      "Epoch 265/400\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.2050 - accuracy: 0.9357\n",
      "Epoch 266/400\n",
      "13/13 [==============================] - 0s 583us/step - loss: 0.2186 - accuracy: 0.9317\n",
      "Epoch 267/400\n",
      "13/13 [==============================] - 0s 626us/step - loss: 0.2279 - accuracy: 0.9197\n",
      "Epoch 268/400\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.2073 - accuracy: 0.9398\n",
      "Epoch 269/400\n",
      "13/13 [==============================] - 0s 530us/step - loss: 0.2246 - accuracy: 0.9357\n",
      "Epoch 270/400\n",
      "13/13 [==============================] - 0s 652us/step - loss: 0.2181 - accuracy: 0.9277\n",
      "Epoch 271/400\n",
      "13/13 [==============================] - 0s 554us/step - loss: 0.2185 - accuracy: 0.9237\n",
      "Epoch 272/400\n",
      "13/13 [==============================] - 0s 664us/step - loss: 0.2232 - accuracy: 0.9237\n",
      "Epoch 273/400\n",
      "13/13 [==============================] - 0s 549us/step - loss: 0.2298 - accuracy: 0.9277\n",
      "Epoch 274/400\n",
      "13/13 [==============================] - 0s 557us/step - loss: 0.2060 - accuracy: 0.9317\n",
      "Epoch 275/400\n",
      "13/13 [==============================] - 0s 534us/step - loss: 0.2030 - accuracy: 0.9398\n",
      "Epoch 276/400\n",
      "13/13 [==============================] - 0s 590us/step - loss: 0.1924 - accuracy: 0.9438\n",
      "Epoch 277/400\n",
      "13/13 [==============================] - 0s 558us/step - loss: 0.1977 - accuracy: 0.9438\n",
      "Epoch 278/400\n",
      "13/13 [==============================] - 0s 565us/step - loss: 0.2349 - accuracy: 0.9197\n",
      "Epoch 279/400\n",
      "13/13 [==============================] - 0s 645us/step - loss: 0.2159 - accuracy: 0.9277\n",
      "Epoch 280/400\n",
      "13/13 [==============================] - 0s 585us/step - loss: 0.2084 - accuracy: 0.9398\n",
      "Epoch 281/400\n",
      "13/13 [==============================] - 0s 594us/step - loss: 0.2267 - accuracy: 0.9237\n",
      "Epoch 282/400\n",
      "13/13 [==============================] - 0s 569us/step - loss: 0.2041 - accuracy: 0.9398\n",
      "Epoch 283/400\n",
      "13/13 [==============================] - 0s 559us/step - loss: 0.2115 - accuracy: 0.9398\n",
      "Epoch 284/400\n",
      "13/13 [==============================] - 0s 591us/step - loss: 0.2210 - accuracy: 0.9277\n",
      "Epoch 285/400\n",
      "13/13 [==============================] - 0s 546us/step - loss: 0.2029 - accuracy: 0.9317\n",
      "Epoch 286/400\n",
      "13/13 [==============================] - 0s 581us/step - loss: 0.2246 - accuracy: 0.9237\n",
      "Epoch 287/400\n",
      "13/13 [==============================] - 0s 532us/step - loss: 0.2152 - accuracy: 0.9317\n",
      "Epoch 288/400\n",
      "13/13 [==============================] - 0s 617us/step - loss: 0.2045 - accuracy: 0.9357\n",
      "Epoch 289/400\n",
      "13/13 [==============================] - 0s 544us/step - loss: 0.2018 - accuracy: 0.9317\n",
      "Epoch 290/400\n",
      "13/13 [==============================] - 0s 581us/step - loss: 0.2157 - accuracy: 0.9277\n",
      "Epoch 291/400\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.2061 - accuracy: 0.9398\n",
      "Epoch 292/400\n",
      "13/13 [==============================] - 0s 562us/step - loss: 0.2153 - accuracy: 0.9317\n",
      "Epoch 293/400\n",
      "13/13 [==============================] - 0s 552us/step - loss: 0.2276 - accuracy: 0.9317\n",
      "Epoch 294/400\n",
      "13/13 [==============================] - 0s 557us/step - loss: 0.1908 - accuracy: 0.9398\n",
      "Epoch 295/400\n",
      "13/13 [==============================] - 0s 602us/step - loss: 0.2040 - accuracy: 0.9398\n",
      "Epoch 296/400\n",
      "13/13 [==============================] - 0s 518us/step - loss: 0.2255 - accuracy: 0.9237\n",
      "Epoch 297/400\n",
      "13/13 [==============================] - 0s 640us/step - loss: 0.2207 - accuracy: 0.9317\n",
      "Epoch 298/400\n",
      "13/13 [==============================] - 0s 566us/step - loss: 0.2378 - accuracy: 0.9116\n",
      "Epoch 299/400\n",
      "13/13 [==============================] - 0s 577us/step - loss: 0.2216 - accuracy: 0.9317\n",
      "Epoch 300/400\n",
      "13/13 [==============================] - 0s 548us/step - loss: 0.2098 - accuracy: 0.9398\n",
      "Epoch 301/400\n",
      "13/13 [==============================] - 0s 612us/step - loss: 0.2133 - accuracy: 0.9277\n",
      "Epoch 302/400\n",
      "13/13 [==============================] - 0s 517us/step - loss: 0.2085 - accuracy: 0.9317\n",
      "Epoch 303/400\n",
      "13/13 [==============================] - 0s 574us/step - loss: 0.2103 - accuracy: 0.9357\n",
      "Epoch 304/400\n",
      "13/13 [==============================] - 0s 628us/step - loss: 0.2220 - accuracy: 0.9237\n",
      "Epoch 305/400\n",
      "13/13 [==============================] - 0s 520us/step - loss: 0.2160 - accuracy: 0.9277\n",
      "Epoch 306/400\n",
      "13/13 [==============================] - 0s 773us/step - loss: 0.2214 - accuracy: 0.9237\n",
      "Epoch 307/400\n",
      "13/13 [==============================] - 0s 589us/step - loss: 0.2049 - accuracy: 0.9438\n",
      "Epoch 308/400\n",
      "13/13 [==============================] - 0s 614us/step - loss: 0.2172 - accuracy: 0.9357\n",
      "Epoch 309/400\n",
      "13/13 [==============================] - 0s 607us/step - loss: 0.2148 - accuracy: 0.9357\n",
      "Epoch 310/400\n",
      "13/13 [==============================] - 0s 593us/step - loss: 0.2109 - accuracy: 0.9357\n",
      "Epoch 311/400\n",
      "13/13 [==============================] - 0s 611us/step - loss: 0.2044 - accuracy: 0.9398\n",
      "Epoch 312/400\n",
      "13/13 [==============================] - 0s 589us/step - loss: 0.1920 - accuracy: 0.9438\n",
      "Epoch 313/400\n",
      "13/13 [==============================] - 0s 631us/step - loss: 0.2086 - accuracy: 0.9398\n",
      "Epoch 314/400\n",
      "13/13 [==============================] - 0s 597us/step - loss: 0.1992 - accuracy: 0.9357\n",
      "Epoch 315/400\n",
      "13/13 [==============================] - 0s 600us/step - loss: 0.2254 - accuracy: 0.9237\n",
      "Epoch 316/400\n",
      "13/13 [==============================] - 0s 586us/step - loss: 0.2026 - accuracy: 0.9398\n",
      "Epoch 317/400\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.2288 - accuracy: 0.9157\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 558us/step - loss: 0.2099 - accuracy: 0.9317\n",
      "Epoch 319/400\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.2286 - accuracy: 0.9277\n",
      "Epoch 320/400\n",
      "13/13 [==============================] - 0s 568us/step - loss: 0.2065 - accuracy: 0.9317\n",
      "Epoch 321/400\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.1891 - accuracy: 0.9438\n",
      "Epoch 322/400\n",
      "13/13 [==============================] - 0s 617us/step - loss: 0.2255 - accuracy: 0.9277\n",
      "Epoch 323/400\n",
      "13/13 [==============================] - 0s 621us/step - loss: 0.2059 - accuracy: 0.9438\n",
      "Epoch 324/400\n",
      "13/13 [==============================] - 0s 535us/step - loss: 0.1945 - accuracy: 0.9438\n",
      "Epoch 325/400\n",
      "13/13 [==============================] - 0s 589us/step - loss: 0.2012 - accuracy: 0.9398\n",
      "Epoch 326/400\n",
      "13/13 [==============================] - 0s 537us/step - loss: 0.1984 - accuracy: 0.9398\n",
      "Epoch 327/400\n",
      "13/13 [==============================] - 0s 660us/step - loss: 0.2096 - accuracy: 0.9277\n",
      "Epoch 328/400\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.2140 - accuracy: 0.9237\n",
      "Epoch 329/400\n",
      "13/13 [==============================] - 0s 547us/step - loss: 0.1958 - accuracy: 0.9478\n",
      "Epoch 330/400\n",
      "13/13 [==============================] - 0s 540us/step - loss: 0.2046 - accuracy: 0.9357\n",
      "Epoch 331/400\n",
      "13/13 [==============================] - 0s 563us/step - loss: 0.1972 - accuracy: 0.9438\n",
      "Epoch 332/400\n",
      "13/13 [==============================] - 0s 582us/step - loss: 0.2055 - accuracy: 0.9317\n",
      "Epoch 333/400\n",
      "13/13 [==============================] - 0s 536us/step - loss: 0.2001 - accuracy: 0.9398\n",
      "Epoch 334/400\n",
      "13/13 [==============================] - 0s 593us/step - loss: 0.1799 - accuracy: 0.9478\n",
      "Epoch 335/400\n",
      "13/13 [==============================] - 0s 529us/step - loss: 0.2122 - accuracy: 0.9317\n",
      "Epoch 336/400\n",
      "13/13 [==============================] - 0s 602us/step - loss: 0.2026 - accuracy: 0.9398\n",
      "Epoch 337/400\n",
      "13/13 [==============================] - 0s 562us/step - loss: 0.2171 - accuracy: 0.9317\n",
      "Epoch 338/400\n",
      "13/13 [==============================] - 0s 581us/step - loss: 0.2023 - accuracy: 0.9317\n",
      "Epoch 339/400\n",
      "13/13 [==============================] - 0s 516us/step - loss: 0.2320 - accuracy: 0.9197\n",
      "Epoch 340/400\n",
      "13/13 [==============================] - 0s 628us/step - loss: 0.2134 - accuracy: 0.9398\n",
      "Epoch 341/400\n",
      "13/13 [==============================] - 0s 531us/step - loss: 0.2176 - accuracy: 0.9317\n",
      "Epoch 342/400\n",
      "13/13 [==============================] - 0s 596us/step - loss: 0.2112 - accuracy: 0.9237\n",
      "Epoch 343/400\n",
      "13/13 [==============================] - 0s 610us/step - loss: 0.2109 - accuracy: 0.9398\n",
      "Epoch 344/400\n",
      "13/13 [==============================] - 0s 513us/step - loss: 0.2153 - accuracy: 0.9317\n",
      "Epoch 345/400\n",
      "13/13 [==============================] - 0s 595us/step - loss: 0.2253 - accuracy: 0.9317\n",
      "Epoch 346/400\n",
      "13/13 [==============================] - 0s 539us/step - loss: 0.2035 - accuracy: 0.9357\n",
      "Epoch 347/400\n",
      "13/13 [==============================] - 0s 617us/step - loss: 0.2125 - accuracy: 0.9357\n",
      "Epoch 348/400\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.1871 - accuracy: 0.9478\n",
      "Epoch 349/400\n",
      "13/13 [==============================] - 0s 589us/step - loss: 0.2224 - accuracy: 0.9317\n",
      "Epoch 350/400\n",
      "13/13 [==============================] - 0s 594us/step - loss: 0.2281 - accuracy: 0.9197\n",
      "Epoch 351/400\n",
      "13/13 [==============================] - 0s 641us/step - loss: 0.2147 - accuracy: 0.9317\n",
      "Epoch 352/400\n",
      "13/13 [==============================] - 0s 610us/step - loss: 0.2056 - accuracy: 0.9398\n",
      "Epoch 353/400\n",
      "13/13 [==============================] - 0s 560us/step - loss: 0.2315 - accuracy: 0.9197\n",
      "Epoch 354/400\n",
      "13/13 [==============================] - 0s 605us/step - loss: 0.2265 - accuracy: 0.9277\n",
      "Epoch 355/400\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.2189 - accuracy: 0.9317\n",
      "Epoch 356/400\n",
      "13/13 [==============================] - 0s 586us/step - loss: 0.2156 - accuracy: 0.9237\n",
      "Epoch 357/400\n",
      "13/13 [==============================] - 0s 588us/step - loss: 0.1961 - accuracy: 0.9438\n",
      "Epoch 358/400\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.2120 - accuracy: 0.9317\n",
      "Epoch 359/400\n",
      "13/13 [==============================] - 0s 539us/step - loss: 0.2080 - accuracy: 0.9357\n",
      "Epoch 360/400\n",
      "13/13 [==============================] - 0s 568us/step - loss: 0.2073 - accuracy: 0.9317\n",
      "Epoch 361/400\n",
      "13/13 [==============================] - 0s 663us/step - loss: 0.2124 - accuracy: 0.9317\n",
      "Epoch 362/400\n",
      "13/13 [==============================] - 0s 542us/step - loss: 0.2040 - accuracy: 0.9357\n",
      "Epoch 363/400\n",
      "13/13 [==============================] - 0s 817us/step - loss: 0.2249 - accuracy: 0.9277\n",
      "Epoch 364/400\n",
      "13/13 [==============================] - 0s 562us/step - loss: 0.2141 - accuracy: 0.9317\n",
      "Epoch 365/400\n",
      "13/13 [==============================] - 0s 551us/step - loss: 0.2102 - accuracy: 0.9357\n",
      "Epoch 366/400\n",
      "13/13 [==============================] - 0s 554us/step - loss: 0.2011 - accuracy: 0.9398\n",
      "Epoch 367/400\n",
      "13/13 [==============================] - 0s 568us/step - loss: 0.2104 - accuracy: 0.9317\n",
      "Epoch 368/400\n",
      "13/13 [==============================] - 0s 601us/step - loss: 0.1976 - accuracy: 0.9438\n",
      "Epoch 369/400\n",
      "13/13 [==============================] - 0s 521us/step - loss: 0.1939 - accuracy: 0.9438\n",
      "Epoch 370/400\n",
      "13/13 [==============================] - 0s 548us/step - loss: 0.2116 - accuracy: 0.9357\n",
      "Epoch 371/400\n",
      "13/13 [==============================] - 0s 545us/step - loss: 0.2321 - accuracy: 0.9277\n",
      "Epoch 372/400\n",
      "13/13 [==============================] - 0s 578us/step - loss: 0.1993 - accuracy: 0.9398\n",
      "Epoch 373/400\n",
      "13/13 [==============================] - 0s 561us/step - loss: 0.2226 - accuracy: 0.9197\n",
      "Epoch 374/400\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.2240 - accuracy: 0.9277\n",
      "Epoch 375/400\n",
      "13/13 [==============================] - 0s 577us/step - loss: 0.2204 - accuracy: 0.9277\n",
      "Epoch 376/400\n",
      "13/13 [==============================] - 0s 582us/step - loss: 0.2072 - accuracy: 0.9317\n",
      "Epoch 377/400\n",
      "13/13 [==============================] - 0s 546us/step - loss: 0.2217 - accuracy: 0.9277\n",
      "Epoch 378/400\n",
      "13/13 [==============================] - 0s 529us/step - loss: 0.2133 - accuracy: 0.9317\n",
      "Epoch 379/400\n",
      "13/13 [==============================] - 0s 573us/step - loss: 0.2211 - accuracy: 0.9277\n",
      "Epoch 380/400\n",
      "13/13 [==============================] - 0s 575us/step - loss: 0.2135 - accuracy: 0.9317\n",
      "Epoch 381/400\n",
      "13/13 [==============================] - 0s 586us/step - loss: 0.2077 - accuracy: 0.9357\n",
      "Epoch 382/400\n",
      "13/13 [==============================] - 0s 534us/step - loss: 0.2193 - accuracy: 0.9237\n",
      "Epoch 383/400\n",
      "13/13 [==============================] - 0s 554us/step - loss: 0.2037 - accuracy: 0.9317\n",
      "Epoch 384/400\n",
      "13/13 [==============================] - 0s 579us/step - loss: 0.2390 - accuracy: 0.9197\n",
      "Epoch 385/400\n",
      "13/13 [==============================] - 0s 690us/step - loss: 0.2114 - accuracy: 0.9237\n",
      "Epoch 386/400\n",
      "13/13 [==============================] - 0s 525us/step - loss: 0.2098 - accuracy: 0.9237\n",
      "Epoch 387/400\n",
      "13/13 [==============================] - 0s 595us/step - loss: 0.2407 - accuracy: 0.9116\n",
      "Epoch 388/400\n",
      "13/13 [==============================] - 0s 599us/step - loss: 0.2035 - accuracy: 0.9277\n",
      "Epoch 389/400\n",
      "13/13 [==============================] - 0s 534us/step - loss: 0.2135 - accuracy: 0.9357\n",
      "Epoch 390/400\n",
      "13/13 [==============================] - 0s 642us/step - loss: 0.2080 - accuracy: 0.9398\n",
      "Epoch 391/400\n",
      "13/13 [==============================] - 0s 563us/step - loss: 0.2097 - accuracy: 0.9398\n",
      "Epoch 392/400\n",
      "13/13 [==============================] - 0s 592us/step - loss: 0.2107 - accuracy: 0.9357\n",
      "Epoch 393/400\n",
      "13/13 [==============================] - 0s 605us/step - loss: 0.2126 - accuracy: 0.9317\n",
      "Epoch 394/400\n",
      "13/13 [==============================] - 0s 595us/step - loss: 0.2186 - accuracy: 0.9277\n",
      "Epoch 395/400\n",
      "13/13 [==============================] - 0s 539us/step - loss: 0.2096 - accuracy: 0.9357\n",
      "Epoch 396/400\n",
      "13/13 [==============================] - 0s 659us/step - loss: 0.2299 - accuracy: 0.9237\n",
      "Epoch 397/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 618us/step - loss: 0.2059 - accuracy: 0.9398\n",
      "Epoch 398/400\n",
      "13/13 [==============================] - 0s 603us/step - loss: 0.2231 - accuracy: 0.9197\n",
      "Epoch 399/400\n",
      "13/13 [==============================] - 0s 562us/step - loss: 0.2098 - accuracy: 0.9357\n",
      "Epoch 400/400\n",
      "13/13 [==============================] - 0s 591us/step - loss: 0.2167 - accuracy: 0.9357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf944a4a50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_np, y_train_np, \n",
    "    epochs = 400, \n",
    "    batch_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-48-40a8d014ce67>:2: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = model.predict(X_test_np)\n",
    "y_pred_prob = model.predict_proba(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579491]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.0359793 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03607818]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.7188402 ]\n",
      " [0.03579488]\n",
      " [0.04161742]\n",
      " [0.03579488]\n",
      " [0.9198317 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.0358299 ]\n",
      " [0.03579488]\n",
      " [0.03579506]\n",
      " [0.03579488]\n",
      " [0.03579494]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.0357956 ]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579542]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.8641771 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579566]\n",
      " [0.06505603]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579485]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.54187804]\n",
      " [0.03644282]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.929633  ]\n",
      " [0.03582945]\n",
      " [0.929633  ]\n",
      " [0.03580153]\n",
      " [0.03579518]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.6670759 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.9173447 ]\n",
      " [0.03579494]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.3922046 ]\n",
      " [0.6670759 ]\n",
      " [0.03579491]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579491]\n",
      " [0.0357949 ]\n",
      " [0.05750805]\n",
      " [0.03706498]\n",
      " [0.0357949 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579491]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.0359793 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03607818]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.7188402 ]\n",
      " [0.03579488]\n",
      " [0.04161742]\n",
      " [0.03579488]\n",
      " [0.9198317 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.0358299 ]\n",
      " [0.03579488]\n",
      " [0.03579506]\n",
      " [0.03579488]\n",
      " [0.03579494]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.0357956 ]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579542]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.8641771 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579566]\n",
      " [0.06505603]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579485]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.54187804]\n",
      " [0.03644282]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.929633  ]\n",
      " [0.03582945]\n",
      " [0.929633  ]\n",
      " [0.03580153]\n",
      " [0.03579518]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.929633  ]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.6670759 ]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.6670759 ]\n",
      " [0.9173447 ]\n",
      " [0.03579494]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.3922046 ]\n",
      " [0.6670759 ]\n",
      " [0.03579491]\n",
      " [0.03579488]\n",
      " [0.03579488]\n",
      " [0.03579491]\n",
      " [0.0357949 ]\n",
      " [0.05750805]\n",
      " [0.03706498]\n",
      " [0.0357949 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_prob)\n",
    "\n",
    "# 별 차이 없음\n",
    "# 지금은 pred가 자동으로 정규화 해주고 있기 때문에!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03579488],\n",
       "       [0.929633  ],\n",
       "       [0.03579488],\n",
       "       [0.03579491],\n",
       "       [0.929633  ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개 데이터만 확인하기\n",
    "\n",
    "y_pred_class[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = y_pred_class > 0.5\n",
    "print(y_pred_class)\n",
    "\n",
    "# 결론적으로,\n",
    "# 독립변수들 베이스로 y값을 재입원할 것이다 안할 것이다를 확인한 것.\n",
    "# 이런 식으로 고객관리를 하면 좋음! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_class.astype(int)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148148148148148\n"
     ]
    }
   ],
   "source": [
    "res = accuracy_score(y_test_np, y_pred_class)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 비교 분석해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_test))\n",
    "\n",
    "# 판다스 형태로 유지되어있음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    87\n",
       "1    21\n",
       "Name: Readmitted, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055555555555556\n",
      "0.19444444444444445\n"
     ]
    }
   ],
   "source": [
    "print(87 / 108)\n",
    "print(21 / 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.805556\n",
       "Name: Readmitted, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts().head(1) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr(거짓 양성률) : 실제로는 해당사항이 없지만 해당사항이 있다고 판정을 내리는 경우\n",
    "# thresholds는 임계치 계산\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.02298851 0.02298851 0.03448276 0.03448276 0.10344828\n",
      " 0.16091954 0.16091954 0.20689655 0.20689655 0.2183908  0.2183908\n",
      " 0.26436782 0.28735632 0.31034483 0.33333333 0.98850575 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.33333333 0.38095238 0.38095238 0.47619048 0.52380952\n",
      " 0.52380952 0.57142857 0.57142857 0.61904762 0.61904762 0.66666667\n",
      " 0.66666667 0.66666667 0.71428571 0.71428571 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.929633   0.929633   0.9198317  0.9173447  0.7188402  0.6670759\n",
      " 0.04161742 0.03706498 0.0358299  0.03582945 0.03580153 0.03579566\n",
      " 0.03579506 0.03579494 0.03579491 0.0357949  0.03579488 0.03579485]\n"
     ]
    }
   ],
   "source": [
    "print(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive rate\")\n",
    "plt.ylabel(\"True Positive rate\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 민감도가 0.4까지는 좋다가 점점 좋지 않아짐. (기울기가 원만해지니까)\n",
    "# 오판율이 점점 높아지고 있음.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC 점수 확인해보기\n",
    "def optimum_threshold(my_threshold):\n",
    "    print(\"Sensitivity:\", tpr[thresholds > my_threshold][-1])\n",
    "    print(\"Specificity:\", 1-fpr[thresholds > my_threshold][-1])\n",
    "    \n",
    "# thresholds > my_threshold\n",
    "# my_threshold는 내가 정한 임계치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.33333333 0.38095238 0.38095238 0.47619048 0.52380952]\n"
     ]
    }
   ],
   "source": [
    "print(tpr[thresholds > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "print(tpr[thresholds > 0.5][-1])\n",
    "\n",
    "# 맨뒤에 값이 무엇인지 출력하라!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.5238095238095238\n",
      "Specificity: 0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "optimum_threshold(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.5238095238095238\n",
      "Specificity: 0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "optimum_threshold(0.5)\n",
    "\n",
    "# 특이도가 꽤 높아짐.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.33333333 0.38095238 0.38095238 0.47619048 0.52380952]\n"
     ]
    }
   ],
   "source": [
    "print(tpr[thresholds > 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.33333333 0.38095238 0.38095238 0.47619048 0.52380952]\n"
     ]
    }
   ],
   "source": [
    "print(tpr[thresholds > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 1.0\n",
      "Specificity: 0.0\n"
     ]
    }
   ],
   "source": [
    "optimum_threshold(0.01)\n",
    "# 임계치가 낮으니까 민감도\n",
    "# 임계치가 작다보니 많은 사람한테 적용은 못함\n",
    "\n",
    "# 민감도 1이니까 참인 케이스는 기가막히게 잡아내는데 아닌 경우는 알 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7575259989053093"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
