{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.3.0.36-cp37-cp37m-manylinux2014_x86_64.whl (43.7 MB)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fontconfig\n",
      "  Downloading fontconfig-0.1.zip (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 947 kB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /home/bitai/anaconda3/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-y1v8v7a4/fontconfig/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-y1v8v7a4/fontconfig/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-install-y1v8v7a4/fontconfig/pip-egg-info\n",
      "         cwd: /tmp/pip-install-y1v8v7a4/fontconfig/\n",
      "    Complete output (6 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-y1v8v7a4/fontconfig/setup.py\", line 9\n",
      "        exec line in glb\n",
      "                ^\n",
      "    SyntaxError: Missing parentheses in call to 'exec'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install fontconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.0\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 4 9 8 6 8 8]\n",
      " [0 7 4 9 4 5 1]\n",
      " [7 9 0 8 6 6 5]\n",
      " [3 1 5 7 8 4 3]\n",
      " [4 1 3 8 0 1 6]\n",
      " [6 8 7 2 1 7 1]\n",
      " [7 1 1 9 8 9 3]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "img = np.random.randint(0, 10, (7, 7))\n",
    "print(img)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "img_np = np.ones([7, 7])\n",
    "\n",
    "print(img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  0 -1]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.array([1, 0, -1])\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(kernel))\n",
    "print(type(img_np))\n",
    "\n",
    "# 영상처리에서 사용하는 컨벌트에서는 불가함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "img_cv = cv2.resize(img_np, (7, 7))\n",
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1]\n",
      " [ 0]\n",
      " [-1]]\n"
     ]
    }
   ],
   "source": [
    "kernel = cv2.resize(kernel, (1, 3))\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img_cv))\n",
    "print(type(kernel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_test)\n",
    "\n",
    "# 1행렬에 convolution을 하면 0이 된다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1]\n",
      " [ 0]\n",
      " [-1]]\n"
     ]
    }
   ],
   "source": [
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 2. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [-1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -2.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "img_cv[0][0] = 0\n",
    "img_cv[3][3] = 2\n",
    "img_cv[6][6] = 3\n",
    "\n",
    "\n",
    "# filter2D - Convolution이 결국 라플라스 변환과 푸리에 변환에 관계를 가지고 있기 때문\n",
    "# Convolution을 통해서 필터를 할 수 있기 때문!\n",
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "print(conv_test)\n",
    "\n",
    "\n",
    "\n",
    "# 이름이 convolution이 아니고 filter2D라고 되어있음\n",
    "# filter는 뭔가를 거르는 것!! \n",
    "# convolution을 하는데 왜 걸러질까?\n",
    "# 프리에 트렌스폼과 convolution이 어떤 관계를 가지고 있음!\n",
    "\n",
    "# 프리에트렌스폼은 스펙트럼 분석을 함.\n",
    "# 스펙트럼 분석을 하면 주파수가 나옴. --> 해당 신호 주파수를 분류할 수 있음.\n",
    "# 스펙트럼은 결국 어떤 영상 성분이 어떤 주파수를 가지고 있다는 얘기!\n",
    "# 무선 신호, 음성 신호 처리할 떄 우리가 말하는 주파수가 4000~7000Hrz\n",
    "# 무슨 말, 어떤 얘기 하는지 분석하려면 스펙트럼 분석해야 함.\n",
    "\n",
    "# 육안으로는 알 수 없으니까 어떤 주파수 대의 성분이 있는지 파악을 하는 것.\n",
    "\n",
    "# 필터 자체를 할 때는 라플라스 트랜스폼\n",
    "# 컴벌루션을 하면 필터링을 하면서 적정한 스펙트럼을 제거할 수 있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter2D 역할을 하는 함수를 만들어보자!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라플라스 변환 => 전달 함수를 얻기 위해 계산함\n",
    "# 입력 대 출력비를 구하겠다.\n",
    "# 입력이 10, 출려기 7, 입출력비 : 7/10 = 0.7\n",
    "# 입력이 y'' = y' + 3y + 2\n",
    "# 출력이 y' = 3e^3x\n",
    "# 라플라스 변환 통해 입출력비를 계산할 수 있게 된다.\n",
    "# integral 0 ~ inf f(t)e^st dt\n",
    "\n",
    "# 1계 미분 방정식(RC 회로)\n",
    "# 라플라스 변환, 푸리에 변환 약식\n",
    "# Low Pass Filter(LPF 설계법) - 1D Convolution\n",
    "# 전달함수 -> 실제 값을 필터링 하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 분류해보기\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(\n",
    "    Conv2D(\n",
    "        32, (3, 3), \n",
    "        input_shape = (64, 64, 3), \n",
    "        activation = 'relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# 컨벌루션 하는 네트워크는 tensor를 쓰는 구나!\n",
    "# 회귀분석은 단순 행렬연산!!\n",
    "# 결과보면 tensor로 나옴!!\n",
    "# 2D convolution보면 tensor쓰는 것을 알 수 있음.\n",
    "\n",
    "\n",
    "# 다시~~\n",
    "# MaxPool2D : 최대 풀링!!!\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 30752)             0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()\n",
    "# 다시~\n",
    "# flatten (Flatten)            (None, 30752)           \n",
    "# 를 보면 플래트닝을 통해 1차원으로 만들어준 것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(128, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(64, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(32, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(16, activation = 'relu')\n",
    ")\n",
    "classifier.add(\n",
    "    Dense(1, activation = 'sigmoid')\n",
    ")\n",
    "classifier.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale = 1.0 / 255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale = 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  dogs\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats  dogs\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainSet = train_gen.flow_from_directory(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/training_set',\n",
    "    target_size = (64, 64), # 위에 만들었던 네트워크도 64, 64로 만들었고, 실제 이미지도 64, 64이기 때문!!\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "testSet = train_gen.flow_from_directory(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson07/Datasets/dataset/test_set',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.5437 - accuracy: 0.7216 - val_loss: 0.5399 - val_accuracy: 0.7175\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.5509 - accuracy: 0.7175 - val_loss: 0.5450 - val_accuracy: 0.7200\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.5494 - accuracy: 0.7128 - val_loss: 0.5267 - val_accuracy: 0.7475\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.5616 - accuracy: 0.6941 - val_loss: 0.5858 - val_accuracy: 0.6975\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.5280 - accuracy: 0.7347 - val_loss: 0.5679 - val_accuracy: 0.7075\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.5225 - accuracy: 0.7403 - val_loss: 0.5466 - val_accuracy: 0.7287\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 10s 100ms/step - loss: 0.5386 - accuracy: 0.7231 - val_loss: 0.5184 - val_accuracy: 0.7375\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.5288 - accuracy: 0.7428 - val_loss: 0.5197 - val_accuracy: 0.7475\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.5227 - accuracy: 0.7356 - val_loss: 0.5760 - val_accuracy: 0.6913\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.5166 - accuracy: 0.7422 - val_loss: 0.5488 - val_accuracy: 0.7100\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.5097 - accuracy: 0.7437 - val_loss: 0.5260 - val_accuracy: 0.7287\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.5021 - accuracy: 0.7497 - val_loss: 0.5443 - val_accuracy: 0.7337\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.5217 - accuracy: 0.7353 - val_loss: 0.5637 - val_accuracy: 0.7050\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.5075 - accuracy: 0.7569 - val_loss: 0.5273 - val_accuracy: 0.7300\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4844 - accuracy: 0.7588 - val_loss: 0.5430 - val_accuracy: 0.7237\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.5012 - accuracy: 0.7528 - val_loss: 0.5265 - val_accuracy: 0.7300\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.5064 - accuracy: 0.7556 - val_loss: 0.5441 - val_accuracy: 0.7150\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.5078 - accuracy: 0.7481 - val_loss: 0.5038 - val_accuracy: 0.7525\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4921 - accuracy: 0.7663 - val_loss: 0.4706 - val_accuracy: 0.7675\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4788 - accuracy: 0.7684 - val_loss: 0.5123 - val_accuracy: 0.7437\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4913 - accuracy: 0.7647 - val_loss: 0.5188 - val_accuracy: 0.7387\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4929 - accuracy: 0.7550 - val_loss: 0.5111 - val_accuracy: 0.7513\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4933 - accuracy: 0.7600 - val_loss: 0.5257 - val_accuracy: 0.7250\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.4880 - accuracy: 0.7547 - val_loss: 0.4871 - val_accuracy: 0.7700\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4583 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7462\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4923 - accuracy: 0.7650 - val_loss: 0.4978 - val_accuracy: 0.7625\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4691 - accuracy: 0.7769 - val_loss: 0.5463 - val_accuracy: 0.7300\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4641 - accuracy: 0.7859 - val_loss: 0.5048 - val_accuracy: 0.7538\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4755 - accuracy: 0.7713 - val_loss: 0.4870 - val_accuracy: 0.7588\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4513 - accuracy: 0.7844 - val_loss: 0.5172 - val_accuracy: 0.7600\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4716 - accuracy: 0.7731 - val_loss: 0.5138 - val_accuracy: 0.7538\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4723 - accuracy: 0.7734 - val_loss: 0.4969 - val_accuracy: 0.7550\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4552 - accuracy: 0.7891 - val_loss: 0.5411 - val_accuracy: 0.7437\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4503 - accuracy: 0.7937 - val_loss: 0.5112 - val_accuracy: 0.7487\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4732 - accuracy: 0.7719 - val_loss: 0.5171 - val_accuracy: 0.7513\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4628 - accuracy: 0.7859 - val_loss: 0.5266 - val_accuracy: 0.7400\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4629 - accuracy: 0.7794 - val_loss: 0.5331 - val_accuracy: 0.7337\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4451 - accuracy: 0.7869 - val_loss: 0.5128 - val_accuracy: 0.7575\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4573 - accuracy: 0.7887 - val_loss: 0.4994 - val_accuracy: 0.7575\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.4449 - accuracy: 0.7897 - val_loss: 0.5039 - val_accuracy: 0.7600\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4530 - accuracy: 0.7881 - val_loss: 0.4976 - val_accuracy: 0.7663\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4640 - accuracy: 0.7794 - val_loss: 0.5049 - val_accuracy: 0.7550\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4479 - accuracy: 0.7869 - val_loss: 0.5098 - val_accuracy: 0.7513\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4503 - accuracy: 0.7941 - val_loss: 0.5092 - val_accuracy: 0.7550\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4476 - accuracy: 0.7925 - val_loss: 0.5103 - val_accuracy: 0.7525\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.4486 - accuracy: 0.7788 - val_loss: 0.5197 - val_accuracy: 0.7550\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4446 - accuracy: 0.7937 - val_loss: 0.4869 - val_accuracy: 0.7750\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4496 - accuracy: 0.7928 - val_loss: 0.5138 - val_accuracy: 0.7513\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4433 - accuracy: 0.7884 - val_loss: 0.4979 - val_accuracy: 0.7713\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.4416 - accuracy: 0.7903 - val_loss: 0.4970 - val_accuracy: 0.7638\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4380 - accuracy: 0.7984 - val_loss: 0.5358 - val_accuracy: 0.7538\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 0.4369 - accuracy: 0.8047 - val_loss: 0.5089 - val_accuracy: 0.7625\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4304 - accuracy: 0.8022 - val_loss: 0.5066 - val_accuracy: 0.7400\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4326 - accuracy: 0.7981 - val_loss: 0.4932 - val_accuracy: 0.7525\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4336 - accuracy: 0.7912 - val_loss: 0.5620 - val_accuracy: 0.7088\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4400 - accuracy: 0.7925 - val_loss: 0.5349 - val_accuracy: 0.7613\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4320 - accuracy: 0.8003 - val_loss: 0.4799 - val_accuracy: 0.7638\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4181 - accuracy: 0.8009 - val_loss: 0.5230 - val_accuracy: 0.7525\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4139 - accuracy: 0.8028 - val_loss: 0.5138 - val_accuracy: 0.7675\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4106 - accuracy: 0.8106 - val_loss: 0.5529 - val_accuracy: 0.7462\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4170 - accuracy: 0.8094 - val_loss: 0.5123 - val_accuracy: 0.7362\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4215 - accuracy: 0.8012 - val_loss: 0.5287 - val_accuracy: 0.7425\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4259 - accuracy: 0.8050 - val_loss: 0.5220 - val_accuracy: 0.7337\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.3995 - accuracy: 0.8112 - val_loss: 0.5086 - val_accuracy: 0.7638\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4348 - accuracy: 0.7994 - val_loss: 0.5561 - val_accuracy: 0.7325\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4157 - accuracy: 0.8128 - val_loss: 0.5061 - val_accuracy: 0.7638\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4122 - accuracy: 0.8041 - val_loss: 0.5272 - val_accuracy: 0.7588\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4039 - accuracy: 0.8138 - val_loss: 0.4857 - val_accuracy: 0.7588\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4117 - accuracy: 0.8072 - val_loss: 0.5606 - val_accuracy: 0.7525\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4176 - accuracy: 0.8109 - val_loss: 0.4774 - val_accuracy: 0.7738\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.3984 - accuracy: 0.8166 - val_loss: 0.4873 - val_accuracy: 0.7825\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4028 - accuracy: 0.8141 - val_loss: 0.4993 - val_accuracy: 0.7625\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4098 - accuracy: 0.8178 - val_loss: 0.5048 - val_accuracy: 0.7550\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4100 - accuracy: 0.8100 - val_loss: 0.5248 - val_accuracy: 0.7437\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3862 - accuracy: 0.8241 - val_loss: 0.5463 - val_accuracy: 0.7250\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.4196 - accuracy: 0.8028 - val_loss: 0.5038 - val_accuracy: 0.7538\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3975 - accuracy: 0.8166 - val_loss: 0.4847 - val_accuracy: 0.7600\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3872 - accuracy: 0.8259 - val_loss: 0.5094 - val_accuracy: 0.7713\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.3925 - accuracy: 0.8213 - val_loss: 0.5061 - val_accuracy: 0.7538\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3888 - accuracy: 0.8169 - val_loss: 0.5603 - val_accuracy: 0.7513\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3986 - accuracy: 0.8191 - val_loss: 0.4914 - val_accuracy: 0.7675\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3805 - accuracy: 0.8291 - val_loss: 0.5003 - val_accuracy: 0.7625\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3937 - accuracy: 0.8303 - val_loss: 0.5172 - val_accuracy: 0.7650\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5296 - val_accuracy: 0.7300\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3881 - accuracy: 0.8216 - val_loss: 0.5081 - val_accuracy: 0.7763\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.3928 - accuracy: 0.8206 - val_loss: 0.4929 - val_accuracy: 0.7800\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 0.3719 - accuracy: 0.8309 - val_loss: 0.4768 - val_accuracy: 0.7912\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3993 - accuracy: 0.8144 - val_loss: 0.5150 - val_accuracy: 0.7588\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.3860 - accuracy: 0.8225 - val_loss: 0.5345 - val_accuracy: 0.7550\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.3783 - accuracy: 0.8306 - val_loss: 0.5587 - val_accuracy: 0.7387\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.3844 - accuracy: 0.8266 - val_loss: 0.4968 - val_accuracy: 0.7825\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3726 - accuracy: 0.8331 - val_loss: 0.5052 - val_accuracy: 0.7650\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.3905 - accuracy: 0.8281 - val_loss: 0.4965 - val_accuracy: 0.7650\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 0.3739 - accuracy: 0.8419 - val_loss: 0.5297 - val_accuracy: 0.7425\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3681 - accuracy: 0.8275 - val_loss: 0.5299 - val_accuracy: 0.7525\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3753 - accuracy: 0.8328 - val_loss: 0.4899 - val_accuracy: 0.7588\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3648 - accuracy: 0.8347 - val_loss: 0.5886 - val_accuracy: 0.7425\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3732 - accuracy: 0.8313 - val_loss: 0.4693 - val_accuracy: 0.7875\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3852 - accuracy: 0.8313 - val_loss: 0.5255 - val_accuracy: 0.7688\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.3659 - accuracy: 0.8394 - val_loss: 0.4720 - val_accuracy: 0.7825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0dca00c1d0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit  ->  다시\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "classifier.fit_generator(\n",
    "    trainSet,\n",
    "    steps_per_epoch = int(10000/batch_size),\n",
    "    epochs = 100,\n",
    "    validation_data = testSet,\n",
    "    validation_steps = int(2500/batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset  'test images'\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson07/Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image.load_img(\n",
    "    'Applied-Deep-Learning-with-Keras/Lesson07/Datasets/test images/test_image_2.jpg',\n",
    "    target_size = (64, 64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "new_image = image.img_to_array(new_image)\n",
    "new_image = np.expand_dims(new_image, axis = 0)\n",
    "\n",
    "result = classifier.predict(new_image)\n",
    "#trainSet.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'Cat'\n",
    "    \n",
    "print(prediction)\n",
    "\n",
    "# convolution 네트워크는 특정 물체 판별하는 인공지는 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
